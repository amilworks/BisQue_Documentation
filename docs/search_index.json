[
["index.html", "Getting Started Cloud Service | Module Development | Python API", " Getting Started Cloud Service | Module Development | Python API Our modules currently span research areas that include Material Science, Biological Science, Biomedical Imaging, and Marine Science. Users can develop and deploy custom state of the art modules by simply containerizing their module with Docker. "],
["docker-installation.html", "Docker Installation", " Docker Installation Docker If you would like to have your own version of BisQue with minimal effort, use the Docker version of BisQue. The source code installation can be found here. Download. Ensure you have the latest release by first running the following pull command: docker pull amilworks/bisque05-caffe-xenial:amil Run. To run the docker version of BisQue locally, start a bisque server on the host port 8080: docker run --name bisque --rm -p 8080:8080 amilworks/bisque05-caffe-xenial:amil and point your browser at http://localhost:8080. You should see a BisQue homepage similar to the one on bisque.ece.ucsb.edu. If you do not see the homepage, check to make sure that port 8080 is not being used by another container or application and that you have correctly mapped the ports using -p 8080:8080, where -p is short for port. Registering Modules. To register all the modules to your local server: Login to your BisQue server using admin:admin Find the module manager under the Admin button on the top right hand corner Put http://localhost:8080/engine_service in the right panel where it says Enter Engine URL and hit Load NOTE: Use localhost:8080 here because it’s internal to the container. Drag and Drop MetaData to the left panel—or whatever module you would like—and the module will now be registered and available for use. You can make the module Public by hitting Set Public in the left panel, which basically means the module is Published and ready for public use. Custom Modules. If you would like to build and test your own module locally, using host mounted modules will make life easier to build, test, debug, and deploy locally. Copy the module directory out of the container and into the folder on your local system named container-modules. docker cp bisque:/source/modules container-modules Copy your module into the container-modules folder on your local system. Restart the container with host mounted modules. Be careful with the command $(pwd)/container-modules that we are using here. If the /container-modules is not in the specified path, you will not see any of the modules during the registration process. docker stop bisque docker run --name bisque --rm -p 8080:8080 -v $(pwd)/container-modules:/source/modules amilworks/bisque05-caffe-xenial:amil Register your module from the above steps in “3. Registering Modules. ”, using the Module Manager. Pushing your Module to Production. If you feel that your module is ready to be added to the production version of BisQue, please feel free to contact us and we will gladly begin the process. Data Storage. Use an external data directory so you don’t lose data when the service stops Uploaded image and workdirs are store in /source/data. You can change this to be a host mounted directory with docker run --name bisque --rm -p 8080:8080 -v $(pwd)/container-data:/source/data amilworks/bisque05-caffe-xenial:amil The default sqlite database is stored inside the container at /source/data/bisque.db The uploaded images are stored inside the container at /source/data/imagedir "],
["intro.html", "1 BisQue Cloud Service", " 1 BisQue Cloud Service Homepage of BisQue. The landing page of BisQue enables users to interact with sample datasets and view the current analysis modules implemented today. BisQue is a web-based platform specifically designed to provide researchers with organizational and quantitative analysis tools for 5D image data. Users can extend Bisque with both data model and analysis extensions in order to adapt the system to local needs. Bisque’s extensibility stems from two core concepts: flexible metadata facility and an open web-based architecture. Together these empower researchers to create, develop and share novel bioimage analyses. Bisque is implemented as a scalable and modular web-service architecture. Image Servers store and manipulate images. Data servers provide flexible metadata storage. Execution servers house executable modules. The client-server architecture seamlessly integrates services across storage and processing hardware. Communication between various components is performed in a RESTful manner through HTTP requests carrying XML and JSON. Web clients use dynamic web components built with AJAX. Backends seamlessly provide access to local resources as well as large scalable resources like Amazon S3 or iRODS for data storage or Condor grids for computation. "],
["how-to-login-or-create-a-new-user.html", "1.1 How to Login or Create a New User", " 1.1 How to Login or Create a New User Homepage of BisQue. The landing page of BisQue enables users to interact with sample datasets and view the current analysis modules implemented today. The top right hand corner shows a drop down to Login or Register New User. Login or Create an Account. After clicking on one of the two options from the dropdown menu above, you will be directed to one of two pages. "],
["how-to-upload-data.html", "1.2 How to Upload Data", " 1.2 How to Upload Data Upload over 200+ Supported File Formats. Step 1. Login Make sure you are logged in. If you are logged in, the MENU bar will include Upload. Step 2. Upload File or Folder Click Upload from the toolbar. There will be two options: Choose File or Choose Directory. Step 3. Build a Dataset Selecting Choose Directory will upload all files in that directory. For example, we selected a folder with three NIFTI files. Uploading a Folder. Once the upload is finished, there will be two options to create a new dataset or add to an existing dataset. Progress of Uploading a Folder. Add to New Dataset If we choose to Add a New Dataset, this means we will create a new dataset with these three files we uploaded. We can always add new data to this dataset later. Creating a New Dataset. Add to Existing Dataset If we choose Add to Existing Dataset, this means we will add these three NIFTI files to an existing dataset on BisQue. We are prompted with all of the datasets we have access to on BisQue: Datasets we created and Datasets other users have created but have made public. Adding to an Existing Dataset. Step 4. Setting Permissions Once we have uploaded the data, we can set permissions for who can access our data. By default, everything is uploaded as Private. If we want to make our data publically available, we can Toggle Permissions. Toggle Permissions. "],
["how-to-add-annotations.html", "1.3 How to Add Annotations", " 1.3 How to Add Annotations Overview Metadata plays a vital role in interpretation, querying, and analysis of images. For example, an experimental condition may highlight differences between images, image resolution may be needed to detect abnormally sized cells and experimenter comments may be handy in finding images of interest. There are many different types of metadata that may be associated with an image such as textual annotations, image-based object outlines and statistical distributions. In order to store the many types of annotations, we use tagging or hierarchical name–value pairs. Flexible and hierarchical tagging is a key feature of Bisque that enables the user to rapidly model diverse experimental information. "],
["how-to-run-a-module.html", "1.4 How to Run a Module", " 1.4 How to Run a Module Running the MetaData Module The Metadata module is a very simple example that annotates an image with its embedded metadata. Refresh the page, go to Analyze and select Metadata module there. Select a single image for test. Execute Run command and observe the updates in the results section "],
["imagej-module.html", "1.5 ImageJ Module", " 1.5 ImageJ Module Overview The ImageJ module allows users to execute arbitrary ImageJ macros on single images or datasets of images. Macro parameters can be changed and parameter value lists can be provided to experiment with parameter variations. The results are stored back in BisQue as Gobjects, tables, or images. Uploading of ImageJ Pipelines Most ImageJ macros can be uploaded and used directly with minor modifications. In order to upload a macro, click “Upload”, select the macro file, and click “Upload”. If the file extension is “.ijm”, the file will automatically be recognized as a CellProfiler macro. As an example, we upload the CometAssay macro developed at the Microscopy Services Laboratory of the University of North Carolina at Chapel Hill, Comet Assay. In order to verify the macro, it can be opened by browsing the imagej_pipeline resources and opening the recently uploaded macro. It will look like this: ImageJ Pipeline Each box represents one ImageJ macro step and the arrows indicate the flow through the steps. Note that some boxes have different colors. For example, the “waitForUser” and “Dialog”-related boxes are shown in red to indicate that they are incompatible with BisQue and will render the macro non-executable. Green boxes indicate regular ImageJ steps that were kept unchanged. Blue boxes are BisQue specific steps (such as “load image from BisQue” or “store table to BisQue”). In order to execute the pipeline, we need to fix the red boxes and then re-upload the pipeline. In this example, the first red boxes correspond to the waitForUser steps of the macro: waitForUser(&quot;Draw an oval around the comet head; Click OK&quot;); run(&quot;Measure&quot;); waitForUser(&quot;Draw an oval around the comet tail; Click OK&quot;); run(&quot;Measure&quot;); Since BisQue modules are currently not interactive, such steps are not allowed. However, since they request user-defined regions for head and tail of the comet to analyze, we can replace them with BisQueLoadPolygon steps: BisQueLoadPolygon(&quot;head&quot;); run(&quot;Measure&quot;); BisQueLoadPolygon(&quot;tail&quot;); run(&quot;Measure&quot;); Each BisQueLoadPolygon step searches for a polygon Gobject in the current image and returns it as an ImageJ selection. The other red boxes correspond to ImageJ “Dialog” functions: Dialog.create(&quot;Do Another?&quot;); Dialog.addCheckbox(&quot;Yes&quot;, true); Dialog.show(); Again, since BisQue is not interactive, these are not allowed. In this example, these steps check if the user wants to analyze more comets. For simplicity, we will simply remove these steps and end the analysis after one iteration. This addresses all red boxes but before being able to run the macro in BisQue, we need to add two important steps: the input and output. For the input, we can just add a new step at the very beginning: BisQueLoadImage(); This will load the current image of the module execution into ImageJ for analysis. Note that for larger datasets of images, the macro will be executed once for each image. For the output, we will store the comet analysis results as a table back into BisQue. This is achieved by adding the following line at the end of the macro: BisQueSaveResults(&quot;comet stats&quot;); This step will read the ImageJ results table and store it in BisQue under the given name. It will be linked in the output section of the current MEX (module execution) document. The completed macro is now as follows: BisQueLoadImage(); run(&quot;Set Measurements...&quot;, &quot;centroid center integrated redirect=None decimal=3&quot;); setFont(&quot;SansSerif&quot;, 18); setColor(255, 255, 255); BisQueLoadPolygon(&quot;head&quot;); run(&quot;Measure&quot;); BisQueLoadPolygon(&quot;tail&quot;); run(&quot;Measure&quot;); i = nResults -1; tailx = getResult(&quot;XM&quot;, i); headx = getResult(&quot;X&quot;, i-1); taily = getResult(&quot;YM&quot;, i); heady = getResult(&quot;Y&quot;, i-1); tailden = getResult(&quot;RawIntDen&quot;,i); headden = getResult(&quot;RawIntDen&quot;,i-1); CometLen = sqrt( ((tailx-headx)* (tailx-headx)) + ((taily-heady)*(taily-heady)) ); setResult(&quot;TailLen&quot;,i,(CometLen)); setResult(&quot;TailMoment&quot;,i , (CometLen * tailden)); setResult(&quot;%TailDNA&quot;,i ,(tailden/(tailden + headden))*100); updateResults(); BisQueSaveResults(&quot;comet stats&quot;); After uploading this macro again, all boxes are either green or blue, indicating the pipeline is now valid for execution. Running an ImageJ Macro ImageJ macros can be run like any other BisQue module. First, select the macro to run (in this example, we select the CometAssay macro. After viewing the pipeline, click on “Analyze” and then on “ImageJ”. The ImageJ module page opens. Click “Select an Image” to choose a single image to run the macro on (alternatively, a dataset of images can be selected to run the macro on multiple images in parallel): ImageJ Pipeline Note that the selected image(s) need to have at least two polygon Gobjects: one with semantic type “head” and one with semantic type “tail”. Finally, click the “Run” button to start the macro execution. Once the execution finishes, the outputs are shown in section 4: ImageJ Pipeline In this case, one table “comet stats” was generated. It contains the comet statistics computed in the macro. Depending on the macro, images or Gobjects can also be generated as output (see next section). The generated tables can now be processed further in additional BisQue modules or shared with other users. Special BisQue extensions for ImageJ There are several BisQue-specific extensions to ImageJ to allow ImageJ macros to interact with the BisQue system. Each one is described in the following. BisQueLoadImage() This function corresponds to the open() function of ImageJ. Instead of opening an image from a file, however, it obtains the image from the BisQue module executor. The opened image is one of the images from the module input section. BisQueLoadPolygon(&quot;gobject type&quot;) This function loads a polygon Gobject from the current image into ImageJ as a selection for further processing in the macro. The “gobject type” parameter is used to select a specific Gobject with the semantic type “gobject type”. In other words, the current image has to have a Gobject as follows: &lt;gobject type=&quot;gobject type&quot;&gt; &lt;polygon&gt; &lt;vertex index=&quot;0&quot; t=&quot;0.0&quot; x=&quot;735.0&quot; y=&quot;617.0&quot; z=&quot;0.0&quot;/&gt; ... &lt;vertex index=&quot;10&quot; t=&quot;0.0&quot; x=&quot;727.0&quot; y=&quot;624.0&quot; z=&quot;0.0&quot;/&gt; &lt;/polygon&gt; &lt;/gobject&gt; This can be generated for example via the graphical annotations tool in the BisQue image viewer. BisQueSaveImage(&quot;image name&quot;) This function corresponds to the saveAs(\"Tiff\", ...) function of ImageJ. Instead of saving the image to a file, however, it stores the image back into BisQue as a new image resource. The created image is then referenced in the MEX (module execution) document’s output section. BisQueSaveROIs(&quot;polygon&quot;, &quot;label&quot;, &quot;color&quot;) This function stores the current ImageJ ROIs as polygon Gobjects in the output section of the current MEX (module execution) document. Each polygon is assigned the provided label and color. BisQueAddTag(&quot;tag_name&quot;, &quot;tag_value&quot;) This function adds a tag/value pair to the output section of the current MEX (module execution) document. BisQueSaveResults() This function stores the current ImageJ result table as a table resource in BisQue. The created table is then referenced in the MEX (module execution) document’s output section. "],
["cellprofiler-module.html", "1.6 CellProfiler Module", " 1.6 CellProfiler Module Overview The CellProfiler module allows to execute arbitrary CellProfiler pipelines on single images or datasets of images. Pipeline parameters can be changed and parameter value lists can be provided to experiment with parameter variations. The results are stored back in BisQue as Gobjects, tables, or images. Uploading of CellProfiler Pipelines Most CellProfiler pipelines can be uploaded and used directly without modifications. In order to upload a pipeline, click Upload, select the pipeline file, and click Upload. If the file extension is .cp or .cppipe, the file will automatically be recognized as a CellProfiler pipeline. In order to verify the pipeline, it can be opened by browsing the cellprofiler_pipeline resources and opening the recently uploaded pipeline. It will look like this: ImageJ Pipeline Each box represents one CellProfiler module and the arrows indicate the pipeline flow through the modules. Note that some boxes have different colors. For example, the first box (BisQueLoadImages) is shown in blue to indicate that the original module(s) from the pipeline have been replaced with a BisQue specific component that allows to read images directly from BisQue. These pipeline conversions happen automatically when the pipeline is uploaded into BisQue. The next three steps in the pipeline are shown in transparent color to indicate that they were inactivated. Certain operations (such as Crop in this example) are not currently compatible with BisQue and are ignored without affecting the rest of the pipeline. Green boxes indicate regular CellProfiler modules that were kept unchanged. Red boxes indicate incompatible operations that could not be modified and will render the pipeline non-executable. The pipeline can be modified to replace the operations in red with other steps and the pipeline re-uploaded to fix this problem. Running a CellProfiler Pipeline In order to demonstrate how to run a CellProfiler pipeline, open the ExampleFly.cppipe pipeline that can be found in the public Fly dataset inside the CellProfiler Examples dataset (please ensure to check Show public data in the options menu on the top right; otherwise, you will not see these resources): ImageJ Pipeline After viewing the pipeline, click on Analyze and then on CellProfiler: ImageJ Pipeline The CellProfiler module page opens. Click Select an Image to choose a single image to run the pipeline on (alternatively, a dataset of images can be selected to run the pipeline on multiple images in parallel): ImageJ Pipeline For this example, we use the image CPExample Fly1. Note that the pipeline expects a three-channel image as input (this can be seen in the BisQueLoadImages step at the beginning of the pipeline). Next, modify any pipeline parameters if desired in section 2 (the values shown are the defaults found in the pipeline). Besides single parameters, this module also allows lists of parameters to be entered. For example, for Size of smoothing filter, one can enter \\([10,20,30]\\) to run the pipeline with all three smoothing filter settings in parallel. This allows to study the effect of this parameter on the final output. Finally, click the Run button to start the pipeline execution. Results Once the execution finishes, the pipeline outputs are shown in section 4: ImageJ Pipeline In this case, one image and one table are generated. Additionally, Gobjects are created by a BisQue specific pipeline step BisQueExtractGObjects towards the end of the pipeline. This step reads certain columns from a generated table and interprets them as GObject parameters (in this case, ellipse coordinates and minor/major axis). The generated GObjects are stored as part of the Mex document, as with any other module. In order to view the Gobjects, open the input image (CPExample Fly1) again and under the Graphical tab, check the top-most CellProfiler line (representing the last module run). This displays three types of ellipses overlayed over the image, one for detected nuclei, one for the cell boundaries, and one for the detected locations of cytoplasm: ImageJ Pipeline The GObjects were generated by the three BisQueExtractGObjects steps at the end of the pipeline, one for objects from the “Nuclei” table, one for objects from the “Cells” table, and one for objects from the Cytoplasm table. The colors were set in these steps as red, green, and blue respectively. By hovering with the mouse pointer over any of the Gobjects, additional statistics are displayed. The generated tables and Gobjects can now be processed further in additional BisQue modules or shared with other users. "],
["plant-cell-segmentation.html", "1.7 Plant Cell Segmentation", " 1.7 Plant Cell Segmentation Overview This module is for segmenting 3D membrane tagged cell images. The workflow is as follows: 3D UNet to output the probability map of a cell boundary, 3D watershed to get the initial cell label, and 3D Conditional Random Field (CRF) to refine the segmentation label. CellECT 2.0 Module Homepage. Here is the landing page for the GPU-enabled CellECT 2.0 module. CellECT 2.0 Module Homepage. Here is the landing page for the GPU-enabled CellECT 2.0 module. Sample Plant Cell Images. These images are taken from time series data stored in TIFF files. Input Sample Plant Cell Images. These images are taken from time series data stored in TIFF files. TIFF Image with minimum \\(z &gt; 1\\) Hyperparameters Threshold - The bilateral standard deviation (threshold) for CRF define how much intensity-homogeneity is required within a region. Higher values allow greater variations under the same label. Label Threshold - The minimum possible volume of cells to avoid segmenting intercellular space as an individual cell. Minimum Distance - In the seeds detection for watershed, the minimum possible distance between two seeds. The lower the value is, the more likely to have over-segmentation. Minimum Cell Size - Cell Features Cell Number - The number of cells in each image stack. Cell Volume - The size of each cell in terms of number of voxels. Cell Center - The centroid of each cell. Cell Coordinates - The surface coordinate of each cell. Adjacency Table - The graph represents the neighbor of each cell 3-way Conjunction Points - The touch points of 3 neighboring cells to a. Output Segmented TIFF Image HDF5 Table with Cell Features tom &lt;- data.frame(&#39;CellNumber&#39;= 1:5, &quot;CellVolume&quot; = c(9832, 2387, 945, 2843, 1029), &quot;CellCenter&quot; = c(&#39;[5, 57, 5]&#39;, &#39;[5, 87, 5]&#39;, &#39;[5, 23, 5]&#39;, &#39;[5, 38, 5]&#39;, &#39;[5, 27, 5]&#39;), &quot;SegmentedImage&quot; = &#39;SEGMENTED TIFF as ARRAY&#39;, &quot;SurfaceCoordinates&quot; = &#39;ARRAY of Surface Coordinates&#39;) knitr::kable(tom, booktabs=TRUE, caption = &quot;Sample HDF5 Table with Cell Features&quot;) TABLE 1.1: Sample HDF5 Table with Cell Features CellNumber CellVolume CellCenter SegmentedImage SurfaceCoordinates 1 9832 [5, 57, 5] SEGMENTED TIFF as ARRAY ARRAY of Surface Coordinates 2 2387 [5, 87, 5] SEGMENTED TIFF as ARRAY ARRAY of Surface Coordinates 3 945 [5, 23, 5] SEGMENTED TIFF as ARRAY ARRAY of Surface Coordinates 4 2843 [5, 38, 5] SEGMENTED TIFF as ARRAY ARRAY of Surface Coordinates 5 1029 [5, 27, 5] SEGMENTED TIFF as ARRAY ARRAY of Surface Coordinates "],
["module-development.html", "2 Module Development", " 2 Module Development BisQue Modules are analysis extensions to the bisque system that allow users to incorporate their own custom analysis scripts written in Python, C++, Java, MATLAB, etc. that perform high-end computations such as deep learning based methods for use by the system and others. One of the main reasons to convert your source code into a BisQue module is for reproducibility. Researchers in the field have exceptional work, but poor coding practices hinders the widespread adoption and justification of their findings. This is by no means their fault, but luckily help is here. Module Files. There are six files that are needed for a module to be built and deployed on the BisQue platform. How to Begin Building Modules STEP 1. Source Code Prep Source Code Building modules requires, of course, source code. Your first order of business is to upload your code to GitHub so you have a copy of your entire codebase in the event rm -rf * happens. Next, verify that your source code and README are clear enough for someone to run and understand. Do not skip this step. I have provided an example README below to get you started. You solved a problem, now share the solution! Project Title One Paragraph of project description goes here Getting Started These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system. Prerequisites What things you need to install the software and how to install them. Probably a requirements.txt, perhaps? Installing A step by step series of examples that tell you how to get a development env running Say what the step will be turn on computer And repeat python module4000.py Deployment Add notes about how to deploy this on a live system Built With Sklearn - Machine Learning Library Contributing Please read CONTRIBUTING.md for details on our code of conduct, and the process for submitting pull requests to us. Versioning GitHub is also good for versioning as well. Use whatever you want. Authors Amil Khan (UCSB BisQue Team) Satish Kumar (UCSB BisQue Team) License This project is licensed under the MIT License - see the LICENSE.md file for details Acknowledgments Hat tip to anyone whose code was used Inspiration etc Once you have working source code that others have tested to make sure it runs, you can begin the process of building your very own BisQue module. STEP 2. Fill Out the Module XML Module XML This file should tell the user what to input. For example, if your module segments pictures of cats and dogs, you should probably have something like this: &lt;tag name=&quot;accepted_type&quot; value=&quot;image&quot; /&gt; Similarly, you should define your output to be what you are outputting. For example, if the output is a segmented image of a dog, you should have something like this: &lt;tag name=&quot;Segmentation&quot; type=&quot;image&quot;&gt; The main purpose of the XML is to put your focus on filling out relevant information instead of learning HTML. BisQue uses the information in the XML to build the user interface for your module so you don’t have to. STEP 3. Write the Dockerfile Dockerfile Probably the most important part to your module—the Dockerfile. Feel free to use example Dockerfiles from the community to get started. The main tasks you need to do are define your working directory as module and COPY all the necessary files needed to run your source code: WORKDIR /module COPY predict_strength.py /module/ # COPY ./source /module/source &lt;--- If you have a source folder There is plenty to do while creating and building the Dockerfile so please read the full description carefully. The best tip we can give you is try to replicate your current setup where your code ran successfully. If you are using Ubuntu 16.04, define that as your base image and continue to build your Dockerfile from there. Now, do not go crazy and add every pip install package you have on your system. Remember, keep your container as light as possible. Only install the necessary packages needed for your source code to run in the container. STEP 4. Modify the Python Script Wrapper Python Script Wrapper Similar to how you would run your source code locally, the PythonScriptWrapper.py will help communicate the input from and output to BisQue. The main change to make is what file does the module need to run for the analysis. For instance, let’s say I have a predict_strength.py file with a predict function that will do everything. Then I would simply import the file and modify the outputs variable to be: outputs = predict( bq, log, **self.options.__dict__ ) Feel free to add any logging and catches you wish while diagnosing your module. This script will be your main point of contact when attempting to pinpoint missing files and dependencies, Python related issues, and many more. Look for the PythonScript.log file when testing your module. STEP 5. Modify the Runtime Config File Runtime Module Configuration Give a name to the module docker container. The other arguments can be left alone. Use this as a means to control versioning. For instance, docker.image = cellseg-3dunet-v2 # ---&gt; cellseg-3dunet-v{} "],
["dockerfile.html", "2.1 Dockerfile", " 2.1 Dockerfile FILENAME: Dockerfile This file will be used for the docker build process so try to keep the default naming convention. Defining a Base Image Typically, a Dockerfile will include a base image such as FROM ubuntu:xenial at the top of the file. We highly recommend using the Ubuntu Xenial 16.04 image for your module as it has been tested rigorously and is the base image we use for BisQue. NOTE. If you would like to use a different Ubuntu flavor like 18.04 Bionic, we encourage you to do so and let us know of any problems you encounter. We typically start off our module Dockerfiles with the following lines: FROM ubuntu:xenial ENV DEBIAN_FRONTEND noninteractive RUN apt-get -y update &amp;&amp; \\ apt-get -y upgrade &amp;&amp; \\ apt-get -y install python APT-GET Installs After these lines, we need to add dependencies for our module such as pip, headers, and any compilers. The next few lines are where we put any apt-get installs. Usually this is good practice since some pip install packages require a compiler. If one is not present in the container, it might be hard to debug what is missing. RUN apt-get -y install python-pip liblapack3 libblas-dev liblapack-dev gfortran RUN apt-get update # &lt;--- Run before pip installs PIP Installs Now we add any pip installs that our module may need such as numpy, pandas, Tensorflow, and any others. If you used a virtual environment to develop module locally, and hopefully you did, then simply use pip freeze &gt; requirements.txt. This will give you a text file with all the packages you are using in your virtual environment for your module. If you are a diligent person, you probably do not use one virtual environment for all your development in, say, Python 3.6. Hence, you will only have the necessary packages in the requirements.txt file. From this file, fill in the necessary pip installs within the Dockerfile. RUN pip install numpy pandas tensorflow RUN pip install scikit-learn==0.19.1 # &lt;--- For specific versions RUN pip install -i https://biodev.ece.ucsb.edu/py/bisque/prod/+simple bisque-api==0.5.9 Working Directory, Source Code We typically define the working directory as follows: WORKDIR /module After this, you can put all of your source code along with the PythonScriptWrapper inside the /modules directory. COPY PythonScriptWrapper /module/ COPY PythonScriptWrapper.py /module/ COPY YOUR_MODULE_SCRIPT.py /module/ # &lt;--- Source folders welcome too COPY pydist /module/pydist/ ENV PATH /module:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin The last line is the ENV instruction which sets the environment variable &lt;key&gt; to the value &lt;value&gt;. This value will be in the environment for all subsequent instructions in the build stage and can be replaced inline in many as well. What Should My Last Line Be? Your last line in the Dockerfile should be the CMD command. There can only be one CMD instruction in a Dockerfile. If you list more than one CMD then only the last CMD will take effect. The main purpose of a CMD is to provide defaults for an executing container. For us, we will use the PythonScriptWrapper as our CMD command as follows: CMD [ &#39;PythonScriptWrapper&#39; ] Simple, am I right? Let’s put all this together in a concrete example. Example: Composite Strength The Composite Strength module requires a variety of special packages, such as a very specific version of scikit-learn==0.19.1. Please be aware that if you do pickle files using scikit-learn, you might have to use the same exact version to unpickle the file. Some of us found that out the hard way, hence the word of caution. This simple mistake can be extended to any number of machine learning tasks. We recommend that for maximum reproducibility, use the exact same version of all pip install packages as you did on your local development environment. Step 1. Define Base Image, Run apt-gets, Install Python Similar to before, we will define our base image of Ubuntu Xenial, run the necessary apt-gets which is crucial, and install Python. FROM ubuntu:xenial ENV DEBIAN_FRONTEND noninteractive RUN apt-get -y update &amp;&amp; \\ apt-get -y upgrade &amp;&amp; \\ apt-get -y install \\ python Step 2. Install Needed apt-get Packages and Dependencies RUN apt-get -y install python-lxml python-numpy RUN apt-get -y install python-pip liblapack3 libblas-dev liblapack-dev gfortran RUN apt-get -y install python-scipy python-configparser python-h5py RUN apt-get update Step 3. Install Needed PIP Packages and Dependencies Best practice is always to have your pip installs defined in the Dockerfile instead of in a requirements.txt. The more self-contained, the better. Additionally, do not forget to install the BQAPI inside the container. RUN pip install pymks tables scipy RUN pip install --user --install-option=&quot;--prefix=&quot; -U scikit-learn==0.19.1 RUN pip install -i https://biodev.ece.ucsb.edu/py/bisque/prod/+simple bisque-api==0.5.9 RUN pip install requests==2.10.0 Step 4. Set Working Directory and COPY Source files The working directory should be defined as /module and in there, dump all your source code. If you want to be clean, use a /source folder in the /module directory. This is your module container and you have the control to customize the structure in any way that seems feasible to you. In this example, there is only one script that performs the entire analysis pipeline. Some might say too simple, others say efficient. WORKDIR /module COPY PythonScriptWrapper /module/ COPY PythonScriptWrapper.py /module/ COPY predict_strength.py /module/ COPY pydist /module/pydist/ ENV PATH /module:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin Step 5. Lastly, the Final Command. Your final command should come as no surprise. The reason we use the PythonScriptWrapper is because it makes life easier for you. Your focus should be on developing breakthrough methods, not how to handshake between a cloud platform and a Docker container. CMD [ &#39;PythonScriptWrapper&#39; ] "],
["module-xml.html", "2.2 Module XML", " 2.2 Module XML FILENAME: NAME_OF_MODULE.xml, where NAME_OF_MODULE is replaced by the name of your module, i.e. Dream3D.xml. The module definition file lays out the interface that the system can call the module with. The simplest form simply lists the name, location and arguments needed to run the modules. Here is an example of a module definition document: Example &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;module name=&quot;MetaData&quot; type=&quot;runtime&quot;&gt; &lt;!-- Comments are OK --&gt; &lt;tag name=&quot;inputs&quot;&gt; &lt;tag name=&quot;image_url&quot; type=&quot;resource&quot;&gt; &lt;template&gt; &lt;tag name=&quot;accepted_type&quot; value=&quot;image&quot; /&gt; &lt;tag name=&quot;accepted_type&quot; value=&quot;dataset&quot; /&gt; &lt;tag name=&quot;label&quot; value=&quot;Image to extract metadata&quot; /&gt; &lt;tag name=&quot;prohibit_upload&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; &lt;/template&gt; &lt;/tag&gt; &lt;tag name=&quot;mex_url&quot; type=&quot;system-input&quot; /&gt; &lt;tag name=&quot;bisque_token&quot; type=&quot;system-input&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;outputs&quot;&gt; &lt;tag name=&quot;metadata&quot; type=&quot;tag&quot;&gt; &lt;template&gt; &lt;tag name=&quot;label&quot; value=&quot;Extracted metadata&quot; /&gt; &lt;/template&gt; &lt;/tag&gt; &lt;/tag&gt; &lt;tag name=&quot;execute_options&quot;&gt; &lt;tag name=&quot;iterable&quot; value=&quot;image_url&quot; type=&quot;dataset&quot; /&gt; &lt;!-- Example for a blocked iteration --&gt; &lt;tag name=&quot;blocked_iter&quot; value=&quot;true&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;module_options&quot; &gt; &lt;tag name=&quot;version&quot; value=&quot;3&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;display_options&quot; &gt; &lt;tag name=&quot;group&quot; value=&quot;Examples&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;help&quot; type=&quot;file&quot; value=&quot;public/help.html&quot; /&gt; &lt;tag name=&quot;thumbnail&quot; type=&quot;file&quot; value=&quot;public/thumbnail.png&quot; /&gt; &lt;tag name=&quot;title&quot; type=&quot;string&quot; value=&quot;MetaData&quot; /&gt; &lt;tag name=&quot;authors&quot; type=&quot;string&quot; value=&quot;The Bisque team&quot; /&gt; &lt;tag name=&quot;description&quot; type=&quot;string&quot; value=&quot;This module annotates an image with its embedded metadata.&quot; /&gt; &lt;/module&gt; The definition above allows the BisQue system to call the module by creating a MEX. The module definition document is actually a templated MEX document. The template parameters in this case are used to render the UI for this module if the user does not want to fully implement the UI. More about this will follow. A module can define inputs and outputs and rely on the automated interface generation or can provide a fully customized user interface delivered by the module server by proxying the data made available by the engine service. Input configurations may also be used by the modules that define their own interfaces since they can call renderers provided by the module service. Module Description Each module has to be described in various ways to be useful. Each module has a number of required, as well as optional parameters it has/may contain. Type in this case can control where the data is coming from, for example default “string” suggests the data is in-place. “file” directs the engine server to look for the file starting in the module root directory. Title &lt;tag name=&quot;title&quot; value=&quot;MetaData&quot; /&gt; Description &lt;tag name=&quot;description&quot; value=&quot;This module annotates an image with its embedded metadata.&quot; /&gt; Authors &lt;tag name=&quot;authors&quot; value=&quot;The Bisque team&quot; /&gt; Thumbnail &lt;tag name=&quot;thumbnail&quot; type=&quot;file&quot; value=&quot;public/thumbnail.png&quot; /&gt; Help An HTML document with a module help that the user can be directed to the document can be inline. &lt;tag name=&quot;help&quot; type=&quot;file&quot; value=&quot;public/help.html&quot; /&gt; Module Options: &lt;tag name=&quot;module_options&quot; &gt; &lt;tag name=&quot;version&quot; value=&quot;2&quot; /&gt; &lt;/tag&gt; Configurations for Images, Datasets, and Resources Label Specifies the label rendered before asking for a resource. &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Accepted Type Defines multiple allowed types of input resource. &lt;tag name=&quot;accepted_type&quot; value=&quot;dataset&quot; /&gt; &lt;tag name=&quot;accepted_type&quot; value=&quot;image&quot; /&gt; Prohibit Upload Used with resources of type image or dataset to specify that the uploader should not be allowed. &lt;tag name=&quot;prohibit_upload&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Example Query Allow a button “from Example” specifies the query string. &lt;tag name=&quot;example_query&quot; value=&quot;*GFAP*&quot; /&gt; Allow Blank Makes resource optional. &lt;tag name=&quot;allow_blank&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Image Specific Configurations Require Geometry Enforce input image geometry. Here the z or t value may be: null or undefined - means it should not be enforced ‘single’ - only one plane is allowed ‘stack’ - only stack is allowed &lt;tag name=&quot;require_geometry&quot;&gt; &lt;tag name=&quot;z&quot; value=&quot;stack&quot; /&gt; &lt;tag name=&quot;t&quot; value=&quot;single&quot; /&gt; &lt;tag name=&quot;fail_message&quot; value=&quot;Only supports 3D images!&quot; /&gt; &lt;/tag&gt; Fail Message Specify a message to show if failed requires validation. &lt;tag name=&quot;fail_message&quot; value=&quot;Only supports 3D images!&quot; /&gt; gobject Specific Configurations Example &lt;gobject name=&quot;tips&quot;&gt; &lt;template&gt; &lt;tag name=&quot;gobject&quot; value=&quot;point&quot; /&gt; &lt;tag name=&quot;require_gobjects&quot;&gt; &lt;tag name=&quot;amount&quot; value=&quot;many&quot; /&gt; &lt;tag name=&quot;fail_message&quot; value=&quot;Requires selection of root tips&quot; /&gt; &lt;/tag&gt; &lt;/template&gt; &lt;/gobject&gt; gobject Defines multiple allowed types of input gobject. &lt;tag name=&quot;gobject&quot; value=&quot;point&quot; /&gt; &lt;tag name=&quot;gobject&quot; value=&quot;polygon&quot; /&gt; Semantic types can also be specified here: &lt;tag name=&quot;gobject&quot; value=&quot;foreground&quot;&gt; &lt;tag name=&quot;color&quot; value=&quot;#00FF00&quot; type=&quot;color&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;gobject&quot; value=&quot;background&quot;&gt; &lt;tag name=&quot;color&quot; value=&quot;#FF0000&quot; type=&quot;color&quot; /&gt; &lt;/tag&gt; Moreover, colors could be proposed for these semantic types to differentiate graphical annotations in modules visually. Users can also force only semantic annotations to be created basically prohibiting creation of primitive graphical elements without semantic meaning: &lt;tag name=&quot;semantic_types&quot; value=&quot;require&quot; /&gt; Require gobjects Validate input gobject. &lt;tag name=&quot;require_gobjects&quot;&gt; &lt;tag name=&quot;amount&quot; value=&quot;many&quot; /&gt; &lt;tag name=&quot;fail_message&quot; value=&quot;Requires select of root tips&quot; /&gt; &lt;/tag&gt; Configuration for require_gobjects consists of: amount - constraint on the amount of objects of allowed type. The amount can take the following values: null or undefined - means it should not be enforced ‘single’ - only one object is allowed ‘many’ - only more than one object allowed ‘oneornone’ - only one or none number - exact number of objects allowed \\(\\leq X\\) - operand followed by a number, accepts: \\(&lt;,&gt;,&lt;=,&gt;=,==\\) Example. Note that \\(&lt;\\) sign should be encoded in an XML attribute. &lt;tag name=&quot;amount&quot; value=&quot;3&quot; type=&quot;number&quot; /&gt; or &lt;tag name=&quot;amount&quot; value=&quot;&gt;=2&quot; /&gt; or &lt;tag name=&quot;amount&quot; value=&quot;&amp;lt;30&quot; /&gt; Fail Message Specify a message to show if failed requires validation. &lt;tag name=&quot;fail_message&quot; value=&quot;Requires select of root tips&quot; /&gt; Color Specify a default color for created gobjects &lt;tag name=&quot;color&quot; value=&quot;#00FFFF&quot; type=&quot;color&quot; /&gt; Example with semantic types and other configuration: &lt;gobject name=&quot;stroke&quot;&gt; &lt;template&gt; &lt;tag name=&quot;gobject&quot; value=&quot;freehand_line&quot; /&gt; &lt;tag name=&quot;gobject&quot; value=&quot;foreground&quot;&gt; &lt;tag name=&quot;color&quot; value=&quot;#00FF00&quot; type=&quot;color&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;gobject&quot; value=&quot;background&quot;&gt; &lt;tag name=&quot;color&quot; value=&quot;#FF0000&quot; type=&quot;color&quot; /&gt; &lt;/tag&gt; &lt;tag name=&quot;semantic_types&quot; value=&quot;require&quot; /&gt; &lt;tag name=&quot;require_gobjects&quot;&gt; &lt;tag name=&quot;amount&quot; value=&quot;&gt;=2&quot; /&gt; &lt;tag name=&quot;fail_message&quot; value=&quot;Requires two polylines; first one inside object of interest (foreground) and second across background.&quot; /&gt; &lt;/tag&gt; &lt;/template&gt; &lt;/gobject&gt; string Specific Configurations Label Specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Units Provides the string and possibly defines conversions, not all types support units, for example boolean does not: &lt;tag name=&quot;units&quot; value=&quot;microns&quot; /&gt; Fail Message Message that will be displayed if failed the check: &lt;tag name=&quot;fail_message&quot; value=&quot;We need a time series image&quot; /&gt; Minimum Length Minimum length of the required string: &lt;tag name=&quot;minLength&quot; value=&quot;10&quot; type=&quot;number&quot; /&gt; Maximum Length Maximum length of the required string: &lt;tag name=&quot;maxLength&quot; value=&quot;100&quot; type=&quot;number&quot; /&gt; Allow Blank Used to allow empty strings, true by default: &lt;tag name=&quot;allowBlank&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Regex Regular expression used to validate input string: &lt;tag name=&quot;regex&quot; value=&quot;[\\w]&quot; /&gt; Default Value Default value of this field: &lt;tag name=&quot;defaultValue&quot; value=&quot;&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; number Specific Configurations A number can select one or more values, in case of selecting multiple values they will be selected using a multi-slider. Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Units Provides the string and possibly defines conversions, not all types support units, for example boolean does not: &lt;tag name=&quot;units&quot; value=&quot;microns&quot; /&gt; Fail Message Message that will be displayed if failed the check: &lt;tag name=&quot;fail_message&quot; value=&quot;We need a time series image&quot; /&gt; Minimum Value Lowest allowed value: &lt;tag name=&quot;minValue&quot; value=&quot;10&quot; type=&quot;number&quot; /&gt; Maximum Value Highest allowed value: &lt;tag name=&quot;maxValue&quot; value=&quot;100&quot; type=&quot;number&quot; /&gt; Allow Decimals Allow to acquire floating point numbers: &lt;tag name=&quot;allowDecimals&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Decimal Precision How many digits after the dot are allowed: &lt;tag name=&quot;decimalPrecision&quot; value=&quot;4&quot; type=&quot;number&quot; /&gt; Default Value Default value of this field: &lt;tag name=&quot;defaultValue&quot; value=&quot;&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Step Step to be used by increment/decrement buttons: &lt;tag name=&quot;step&quot; value=&quot;1&quot; type=&quot;number&quot; /&gt; Show Slider Allows hiding the slider in case of single value picking: &lt;tag name=&quot;showSlider&quot; value=&quot;false&quot; type=&quot;boolean&quot; /&gt; Hide Number Picker Allows hiding the number selection box if only slider is preferred: &lt;tag name=&quot;hideNumberPicker&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Multiple Values Using multiple values: &lt;tag name=&quot;myrange&quot; type=&quot;number&quot; &gt; &lt;value&gt;5.6&lt;/value&gt; &lt;value&gt;12&lt;/value&gt; &lt;value&gt;14&lt;/value&gt; &lt;/tag&gt; combo Specific Configurations Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Units Provides the string and possibly defines conversions, not all types support units, for example boolean does not: &lt;tag name=&quot;units&quot; value=&quot;microns&quot; /&gt; Select Specifies a list of select elements, provide as many as you need, this might have to be implemented as a list of values?: &lt;tag name=&quot;select&quot; value=&quot;Alaska&quot; /&gt; &lt;tag name=&quot;select&quot; value=&quot;California&quot; /&gt; Passed Values Specifies a list of values passed for the corresponding select elements, this might have to be implemented as a list of values?: &lt;tag name=&quot;select&quot; value=&quot;AL&quot; /&gt; &lt;tag name=&quot;select&quot; value=&quot;CA&quot; /&gt; Failed Value If the combo’s value is same as fail_value, combo’s input is considered invalid and the fail_message is displayed: &lt;tag name=&quot;fail_value&quot; value=&quot;Select a choice...&quot; /&gt; Fail Message Error message that will be displayed if combo’s value is null or same as fail_value: &lt;tag name=&quot;fail_message&quot; value=&quot;User needs to select a choice!&quot; /&gt; Editable Allows a combo box string to be edited directly and would allow input of values not existent in the select list: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; boolean Specific Configurations Label - simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Fail Message Message that will be displayed if failed the check: &lt;tag name=&quot;fail_message&quot; value=&quot;We need a time series image&quot; /&gt; Default Value Default value of this field: &lt;tag name=&quot;defaultValue&quot; value=&quot;&quot; type=&quot;boolean&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; date Specific Configurations This renderer allow you to pick both date and time. NOTE. Value contains a string in ISO standard, ex: YYYY:MM:DDThh:mm:ss No Date Can hide the date picker: &lt;tag name=&quot;nodate&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; No Time Can hide the time picker: &lt;tag name=&quot;notime&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Fail Message Message that will be displayed if failed the check: &lt;tag name=&quot;fail_message&quot; value=&quot;We need a time series image&quot; /&gt; Format Date format used by this field, default value is : YYYY:MM:DDThh:mm:ss &lt;tag name=&quot;format&quot; value=&quot;YYYY:MM:DDThh:mm:ss&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; hyperlink Specific Configurations Default Value Default value of this field: &lt;tag name=&quot;defaultValue&quot; value=&quot;&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; email Specific Configurations Default Value Default value of this field: &lt;tag name=&quot;defaultValue&quot; value=&quot;&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; bisqueresource Specific Configurations Resource Type Type of bisque resource to be selected, image by default: &lt;tag name=&quot;resourceType&quot; value=&quot;image&quot; /&gt; Default Value Default value of this field: &lt;tag name=&quot;defaultValue&quot; value=&quot;&quot; /&gt; Editable Whether this field is editable by the user, true by default: &lt;tag name=&quot;editable&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; annotation_status Specific Configurations This element allows marking resources with annotation status as: STARTED FINISHED APPROVED image_channel Specific Configurations Example: &lt;tag name=&quot;nuclear_channel&quot; value=&quot;1&quot; type=&quot;image_channel&quot;&gt; &lt;template&gt; &lt;tag name=&quot;label&quot; value=&quot;Nuclear channel&quot; /&gt; &lt;tag name=&quot;reference&quot; value=&quot;resource_url&quot; /&gt; &lt;tag name=&quot;guess&quot; value=&quot;nuc|Nuc|dapi|DAPI|405|dna|DNA|Cy3&quot; /&gt; &lt;tag name=&quot;fail_message&quot; value=&quot;You need to select image channel&quot; /&gt; &lt;tag name=&quot;allowNone&quot; value=&quot;false&quot; type=&quot;boolean&quot; /&gt; &lt;tag name=&quot;description&quot; value=&quot;Select an image channel representing nulcei&quot; /&gt; &lt;/template&gt; &lt;/tag&gt; Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Fail Message Message that will be displayed if failed the check: &lt;tag name=&quot;fail_message&quot; value=&quot;You need to select a channel&quot; /&gt; Reference Name of the input resource that should be used to initialize this selector: &lt;tag name=&quot;reference&quot; value=&quot;resource_url&quot;/&gt; Guess Regular expression used to guess which channel should be selected by default: &lt;tag name=&quot;guess&quot; value=&quot;nuc|Nuc|dapi|DAPI|405|dna|DNA|Cy3&quot;/&gt; Allow None Allows selection of ‘None’ channel, used for optional channel selection: &lt;tag name=&quot;allowNone&quot; value=&quot;true&quot; type=&quot;boolean&quot; /&gt; pixel_resolution Specific Configurations This element must have for values that represent X, Y, Z and T resolution values in microns, microns, microns and seconds respectively. Example: &lt;tag name=&quot;pixel_resolution&quot; type=&quot;pixel_resolution&quot;&gt; &lt;value&gt;0&lt;/value&gt; &lt;value&gt;0&lt;/value&gt; &lt;value&gt;0&lt;/value&gt; &lt;value&gt;0&lt;/value&gt; &lt;template&gt; &lt;tag name=&quot;label&quot; value=&quot;Voxel resolution&quot; /&gt; &lt;tag name=&quot;reference&quot; value=&quot;resource_url&quot; /&gt; &lt;tag name=&quot;units&quot; value=&quot;microns&quot; /&gt; &lt;tag name=&quot;description&quot; value=&quot;This is a default voxel resolution and is only used during the dataset run if the image does not have one.&quot; /&gt; &lt;/template&gt; &lt;/tag&gt; Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Fail Message Message that will be displayed if failed the check: &lt;tag name=&quot;fail_message&quot; value=&quot;You need to select a channel&quot; /&gt; Reference Name of the input resource that should be used to initialize this selector: &lt;tag name=&quot;reference&quot; value=&quot;resource_url&quot;/&gt; Units Provides the string and possibly defines conversions, not all types support units, for example boolean does not: &lt;tag name=&quot;units&quot; value=&quot;microns&quot; /&gt; Description Used to show tool tip information: &lt;tag name=&quot;description&quot; value=&quot;This is a default voxel resolution and is only used during the dataset run if the image does not have one.&quot; /&gt; annotation_attr Specific Configurations This element allows select attributes of annotations (tags/gobjects) from either whole database or constrained by a dataset. For example it can be used to select a type out of a list of all types of graphical annotations. Example: &lt;tag name=&quot;gob_types&quot; value=&quot;&quot; type=&quot;annotation_attr&quot;&gt; &lt;tag name=&quot;template&quot; type=&quot;template&quot;&gt; &lt;tag name=&quot;label&quot; value=&quot;Graphical types&quot; /&gt; &lt;tag name=&quot;allowBlank&quot; value=&quot;false&quot; type=&quot;boolean&quot; /&gt; &lt;tag name=&quot;reference_dataset&quot; value=&quot;dataset_url&quot; /&gt; &lt;tag name=&quot;reference_type&quot; value=&quot;annotation_type&quot; /&gt; &lt;tag name=&quot;reference_attribute&quot; value=&quot;annotation_attribute&quot; /&gt; &lt;tag name=&quot;element&quot; value=&quot;gobject&quot; /&gt; &lt;tag name=&quot;attribute&quot; value=&quot;type&quot; /&gt; &lt;tag name=&quot;dataset&quot; value=&quot;/data_service/&quot; /&gt; &lt;/tag&gt; &lt;/tag&gt; Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Reference Dataset Name of the input resource that can be used to initialize this selector’s constrained query: &lt;tag name=&quot;reference_dataset&quot; value=&quot;resource_url&quot;/&gt; Reference Type Name of the type selector that can be used to initialize this selector’s constrained query: &lt;tag name=&quot;reference_type&quot; value=&quot;type_combo&quot;/&gt; Reference Attribute Name of the attribute selector that can be used to initialize this selector’s constrained query: &lt;tag name=&quot;reference_attribute&quot; value=&quot;attrib_combo&quot;/&gt; Element Default value for the element to constraine query: &lt;tag name=&quot;element&quot; value=&quot;gobject&quot; /&gt; Attribute Default value for the attribute to constrain query: &lt;tag name=&quot;attribute&quot; value=&quot;type&quot; /&gt; Dataset Default value for the dataset to constrain query: &lt;tag name=&quot;dataset&quot; value=&quot;/data_service/&quot; /&gt; mex Specific Configurations This element selects a previously run module execution in order to chain modules. Example: &lt;tag name=&quot;mex_url&quot; type=&quot;mex&quot;&gt; &lt;template&gt; &lt;tag name=&quot;label&quot; value=&quot;Select input MEX&quot; /&gt; &lt;tag name=&quot;query&quot; value=&quot;&amp;amp;name=NuclearDetector3D&quot; /&gt; &lt;/template&gt; &lt;/tag&gt; Label Simply specifies the label rendered before asking for a resource: &lt;tag name=&quot;label&quot; value=&quot;Select input image&quot; /&gt; Description Provides larger description shown in the tool-tip: &lt;tag name=&quot;description&quot; value=&quot;This variable is very important...&quot; /&gt; Query A query string that would narrow MEX search: &lt;tag name=&quot;query&quot; value=&quot;&amp;amp;name=NuclearDetector3D&quot; /&gt; Query Selected Resource This option allows MEX selector to pretend it is an image resource selector by finding the name of the required resource in the selected MEX and emitting selection signal. This can be used for MEX selectors that would like to init image resolution or image channel pickers based on an input MEX: &lt;tag name=&quot;query_selected_resource&quot; value=&quot;resource_url&quot; /&gt; Data-Parallel Execution It is possible to execute any module in a data-parallel way by passing a dataset instead of an individual image. In order to do this you need to: Indicate the resource that can be iterated on Allow that resource to accept datasets and possibly Configure renderers for iterated run &lt;!-- allow iterable resource to accept datasets --&gt; &lt;tag name=&quot;inputs&quot;&gt; &lt;tag name=&quot;image_url&quot; type=&quot;resource&quot;&gt; &lt;template&gt; &lt;tag name=&quot;accepted_type&quot; value=&quot;image&quot; /&gt; &lt;tag name=&quot;accepted_type&quot; value=&quot;dataset&quot; /&gt; ... &lt;/template&gt; &lt;/tag&gt; ... &lt;/tag&gt; ... &lt;!-- configure renderers for iterated run --&gt; &lt;tag name=&quot;outputs&quot;&gt; ... &lt;!-- Iterated outputs --&gt; &lt;tag name=&quot;mex_url&quot; type=&quot;mex&quot; /&gt; &lt;tag name=&quot;resource_url&quot; type=&quot;dataset&quot; /&gt; &lt;/tag&gt; ..... &lt;!-- indicate the resource that can be iterated --&gt; &lt;tag name=&quot;execute_options&quot;&gt; &lt;tag name=&quot;iterable&quot; value=&quot;image_url&quot; type=&quot;dataset&quot; /&gt; &lt;/tag&gt; This definition is used by the module UI to add a dataset selector for this image and let module server know by sending a proper MEX that this resource should be iterated upon. Module server will create a parallel execution iterating over the selected dataset and creating an output MEX with sub MEXes for each individual image. Other Data-Parallel Types One can also request parallel execution over resource types other than dataset. For example a very useful would be to request iteration over a MEX, where a module could accept parallelized MEX as input and iterate over sub-MEXs for parallelized processing of results. In order to do that we need to indicate the type of the input resource and additionally provide an xpath expression within that resource to find elements we would like to iterate over: &lt;tag name=&quot;execute_options&quot;&gt; &lt;tag name=&quot;iterable&quot; value=&quot;input_mex&quot; type=&quot;mex&quot; &gt; &lt;tag name=&quot;xpath&quot; value=&quot;./mex/@uri&quot; /&gt; &lt;/tag&gt; &lt;/tag&gt; "],
["python-script-wrapper.html", "2.3 Python Script Wrapper", " 2.3 Python Script Wrapper FILENAME: PythonScriptWrapper.py Example. Python Script Wrapper Imports The main imports for the PythonScriptWrapper are mostly for logging and communicating with BisQue. In this code snippet, the line from NAME_OF_MODULE import predict_function is importing a prediction function from a single Python file. If multiple functions need to be imported from a source folder, make sure there is an __init__.py or there will be import errors. import sys import io from lxml import etree import optparse import logging from NAME_OF_MODULE import predict_function logging.basicConfig(filename=&#39;PythonScript.log&#39;,filemode=&#39;a&#39;,level=logging.DEBUG) log = logging.getLogger(&#39;bq.modules&#39;) from bqapi.comm import BQCommError from bqapi.comm import BQSession Python Script Wrapper Class The class contains all of the functions needed to initialize, run, and save the module results back to BisQue as a resource. For instance, if the output is an image, the resource would be of type image and uploaded to BisQue as an image. class PythonScriptWrapper(object): def run(self): &quot;&quot;&quot; Run Python script &quot;&quot;&quot; bq = self.bqSession # call script outputs = predict_function( bq, log, **self.options.__dict__ ) # save output back to BisQue for output in outputs: self.output_resources.append(output) def setup(self): &quot;&quot;&quot; Pre-run initialization &quot;&quot;&quot; self.bqSession.update_mex(&#39;Initializing...&#39;) self.mex_parameter_parser(self.bqSession.mex.xmltree) self.output_resources = [] def teardown(self): &quot;&quot;&quot; Post the results to the mex xml &quot;&quot;&quot; self.bqSession.update_mex( &#39;Returning results&#39;) outputTag = etree.Element(&#39;tag&#39;, name =&#39;outputs&#39;) for r_xml in self.output_resources: if isinstance(r_xml, basestring): r_xml = etree.fromstring(r_xml) res_type = r_xml.get(&#39;type&#39;, None) or r_xml.get(&#39;resource_type&#39;, None) or r_xml.tag # append reference to output if res_type in [&#39;table&#39;, &#39;image&#39;]: outputTag.append(r_xml) #etree.SubElement(outputTag, &#39;tag&#39;, name=&#39;output_table&#39; if res_type==&#39;table&#39; else &#39;output_image&#39;, type=res_type, value=r_xml.get(&#39;uri&#39;,&#39;&#39;)) else: outputTag.append(r_xml) #etree.SubElement(outputTag, r_xml.tag, name=r_xml.get(&#39;name&#39;, &#39;_&#39;), type=r_xml.get(&#39;type&#39;, &#39;string&#39;), value=r_xml.get(&#39;value&#39;, &#39;&#39;)) self.bqSession.finish_mex(tags=[outputTag]) def mex_parameter_parser(self, mex_xml): &quot;&quot;&quot; Parses input of the xml and add it to options attribute (unless already set) @param: mex_xml &quot;&quot;&quot; # inputs are all non-&quot;script_params&quot; under &quot;inputs&quot; and all params under &quot;script_params&quot; mex_inputs = mex_xml.xpath(&#39;tag[@name=&quot;inputs&quot;]/tag[@name!=&quot;script_params&quot;] | tag[@name=&quot;inputs&quot;]/tag[@name=&quot;script_params&quot;]/tag&#39;) if mex_inputs: for tag in mex_inputs: if tag.tag == &#39;tag&#39; and tag.get(&#39;type&#39;, &#39;&#39;) != &#39;system-input&#39;: #skip system input values if not getattr(self.options,tag.get(&#39;name&#39;, &#39;&#39;), None): log.debug(&#39;Set options with %s as %s&#39;%(tag.get(&#39;name&#39;,&#39;&#39;),tag.get(&#39;value&#39;,&#39;&#39;))) setattr(self.options,tag.get(&#39;name&#39;,&#39;&#39;),tag.get(&#39;value&#39;,&#39;&#39;)) else: log.debug(&#39;No Inputs Found on MEX!&#39;) def validate_input(self): &quot;&quot;&quot; Check to see if a mex with token or user with password was provided. @return True is returned if validation credention was provided else False is returned &quot;&quot;&quot; if (self.options.mexURL and self.options.token): #run module through engine service return True if (self.options.user and self.options.pwd and self.options.root): #run module locally (note: to test module) return True log.debug(&#39;Insufficient options or arguments to start this module&#39;) return False Main Function The main function enables the communication between BisQue and the module. For example, when a module is run under a user, we need to make sure that the unique ID is registered with the user. def main(self): parser = optparse.OptionParser() parser.add_option(&#39;--mex_url&#39; , dest=&quot;mexURL&quot;) parser.add_option(&#39;--module_dir&#39; , dest=&quot;modulePath&quot;) parser.add_option(&#39;--staging_path&#39; , dest=&quot;stagingPath&quot;) parser.add_option(&#39;--bisque_token&#39; , dest=&quot;token&quot;) parser.add_option(&#39;--user&#39; , dest=&quot;user&quot;) parser.add_option(&#39;--pwd&#39; , dest=&quot;pwd&quot;) parser.add_option(&#39;--root&#39; , dest=&quot;root&quot;) (options, args) = parser.parse_args() fh = logging.FileHandler(&#39;scriptrun.log&#39;, mode=&#39;a&#39;) fh.setLevel(logging.DEBUG) formatter = logging.Formatter(&#39;[%(asctime)s] %(levelname)8s --- %(message)s &#39; + &#39;(%(filename)s:%(lineno)s)&#39;,datefmt=&#39;%Y-%m-%d %H:%M:%S&#39;) fh.setFormatter(formatter) log.addHandler(fh) try: #pull out the mex if not options.mexURL: options.mexURL = sys.argv[-2] if not options.token: options.token = sys.argv[-1] except IndexError: #no argv were set pass if not options.stagingPath: options.stagingPath = &#39;&#39; log.info(&#39;\\n\\nPARAMS : %s \\n\\n Options: %s&#39; % (args, options)) self.options = options if self.validate_input(): #initalizes if user and password are provided if (self.options.user and self.options.pwd and self.options.root): self.bqSession = BQSession().init_local( self.options.user, self.options.pwd, bisque_root=self.options.root) self.options.mexURL = self.bqSession.mex.uri #initalizes if mex and mex token is provided elif (self.options.mexURL and self.options.token): self.bqSession = BQSession().init_mex(self.options.mexURL, self.options.token) else: raise ScriptError(&#39;Insufficient options or arguments to start this module&#39;) try: self.setup() except Exception as e: log.exception(&quot;Exception during setup&quot;) self.bqSession.fail_mex(msg = &quot;Exception during setup: %s&quot; % str(e)) return try: self.run() except (Exception, ScriptError) as e: log.exception(&quot;Exception during run&quot;) self.bqSession.fail_mex(msg = &quot;Exception during run: %s&quot; % str(e)) return try: self.teardown() except (Exception, ScriptError) as e: log.exception(&quot;Exception during teardown&quot;) self.bqSession.fail_mex(msg = &quot;Exception during teardown: %s&quot; % str(e)) return self.bqSession.close() if __name__==&quot;__main__&quot;: PythonScriptWrapper().main() "],
["source-code.html", "2.4 Source Code", " 2.4 Source Code You can have all your files in a /source folder or have one Python, MATLAB, C++, etc. file. In the case where the source code is in one file, it makes less sense to put the file in a /source directory. However, when the source code is spread across multiple files and directories, using a /source directory will make life easier and more organized. Example. Composite Strength Module Let’s take a look at the structure of the Composite Strength module. In this example, we only have one Python file that contains all of our source code, predict_strength.py. TwoPhasePrediction/ ├── Dockerfile ├── PythonScriptWrapper ├── PythonScriptWrapper.py ├── TwoPhasePrediction.xml ├── predict_strength.py # &lt;----- Source file ├── public │ ├── help.html │ ├── marat_workflow.png │ ├── thumbnail.png │ ├── webapp.css │ └── webapp.js ├── runtime-module.cfg └── setup.py "],
["runtime-module-configuration.html", "2.5 Runtime Module Configuration", " 2.5 Runtime Module Configuration FILENAME: runtime-module.cfg The runtime module configuration file only has one line that needs to be changed: docker.image = NAME_OF_MODULE This should be the name of the docker image of the module. Hence, when the module is run, it will look for that specific docker image. Good practice would be to use different names when the module is updated NAME_OF_MODULE-v2 or include a tag, such as stable or latest. # Module configuration file for local execution of modules runtime.platforms = command # Module configuration file for local execution of modules module_enabled = True runtime.platforms=command [command] docker.image = NAME_OF_MODULE environments = Staged,Docker executable = python PythonScriptWrapper.py files = pydist, PythonScriptWrapper.py Example. Composite Strength Module In this example, we see that the name of the docker image is predict_strength. So, when a user hits Run on the Composite Strength module page, BisQue will always pull the latest image of predict_strength. # Module configuration file for local execution of modules runtime.platforms = command # Module configuration file for local execution of modules module_enabled = True runtime.platforms=command [command] docker.image = predict_strength environments = Staged,Docker executable = python PythonScriptWrapper.py files = pydist, PythonScriptWrapper.py "],
["python-setup.html", "2.6 Python Setup", " 2.6 Python Setup FILENAME: setup.py The only changes to make in this file are naming. Specifically, this line: docker_setup(&#39;Composite_Strength&#39;, &#39;TwoPhasePrediction&#39;, &#39;twophaseprediction&#39;, params=params) NOTE: Before running python setup.py, please make sure that all the files are created and configured correctly. If not, save yourself hours of troubleshooting by going through the other file tutorials. import sys from bq.setup.module_setup import python_setup, docker_setup, require, read_config def setup(params, *args, **kw): python_setup(&#39;PythonScriptWrapper.py&#39;, params=params) docker_setup(&#39;Composite_Strength&#39;, &#39;TwoPhasePrediction&#39;, &#39;twophaseprediction&#39;, params=params) if __name__ ==&quot;__main__&quot;: params = read_config(&#39;runtime-bisque.cfg&#39;) if len(sys.argv)&gt;1: params = eval (sys.argv[1]) sys.exit(setup(params)) "],
["bqapi.html", "3 BQAPI", " 3 BQAPI PIP Install pip install -i https://biodev.ece.ucsb.edu/py/bisque/prod/+simple bisque_api BQAPI provides bisque users with a means to extract features from resources using the feature service. Below is information on the Python API and a few example on how to use it. FeatureResource(image=None, mask=None, gobject=None) Named tuple to make it easier to organize resources. Of course, one can always just make a simple list of tuples for the resource list. class Feature() The Feature class is the base implementation of the feature service API for when one need to extract a set of features on a small set of resources. BQSession is used as the communication layer for bqfeatures, therefore before making any requests a local BQSession has to be instantiated to pass to any feature request. fetch(session, name, resource_list, path=None) Requests the feature server to calculate features on provided resources. Input session - a local instantiated BQSession attached to a MEX. name - the name of the feature one wishes to extract. resource_list - list of the resources to extract. Format: [(image_url, mask_url, gobject_url),…] if a parameter is not required just provided None. path - the location were the HDF5 file is stored. If None is set, the file will be placed in a temporary file and a Pytables file handle will be returned. (default: None) Output return - returns either a Pytables file handle or the file name when the path is provided Lets upload an image an calculate a single feature on it. import os from bqapi.comm import BQSession from bqapi.bqfeature import Feature, FeatureResource # initialize local session session = BQSession().init_local(user, pwd, bisque_root=&#39;http://bisque.ece.ucsb.edu&#39;) #post image to bisque and get the response response_xml = session.postblob(&#39;myimage.jpg&#39;) #construct resource list of the image just uploaded resource_list = [FeatureResource(image=&#39;http://bisque.ece.ucsb.edu/image_service/%s&#39; % response_xml.attrib[&#39;resource_uniq&#39;])] #fetch features on image resource pytables_response = Feature().fetch(session, &#39;HTD&#39;, resource_list) #get a numpy list of features for the downloaded HDF5 file. feature = pytables_response.root.values[:][&#39;feature&#39;] #close and remove the HDF5 file since it is stored in a tempfile pytables_response.close() os.remove(pytables_response.filename) fetch_vector(session, name, resource_list) Requests the feature server to calculate features on provided resources. Designed more for requests of very few features since all the features will be loaded into memory. Input session - a local instantiated BQSession attached to a MEX. name - the name of the feature one wishes to extract resource_list - list of the resources to extract. format: [(image_url, mask_url, gobject_url),…] if a parameter is not required just provided None Output return - a list of features as numpy array length(session, name) Static method that returns the length of the feature requested. Input session - a local instantiated BQSession attached to a MEX. name - the name of the feature one wishes to extract Output return feature length "],
["download-an-array.html", "Download an Array", " Download an Array Access an HDF5 Table from BisQue In this example, we will show you how to use the BQAPI to download a multidimensional array from within an HDF file and return it as a numpy array in Python. The API call goes as follows: Get the logger Instantiate a BisQue session Login using USERNAME and PASSWORD Instantiate the table service Use the table service to load the array Return the array Step 0. Import Dependencies Before we can even attempt anything cool with the API, we need to import the necessary packages. In this case, we need the following packages: import numpy as np import logging from bqapi.services import tables from bqapi import BQSession from bqapi.util import fetch_blob from bqapi.comm import BQCommError from bqapi.comm import BQSession Place these at the top of your Jupyter notebook or Python script to ensure these run first. If you have not installed the BQAPI via pip, then install the BQAPI here. Step 1. Get the Logger The logger service allows us to debug if anything goes wrong during the process of pulling our array. We use this in the BisQue core development as well, so feel free to gain greater insight into our other logger services as well. We will define the get_table logger here. log = logging.getLogger(&#39;get_table&#39;) Step 2. Instantiate a BisQue session This instantiation enables the user to effectively communicate with BisQue. Without this, you will not be able to login and interact with the API. bq = BQSession() Step 3. Login using BisQue Credentials Here is where we will login into our BisQue account to access the data we have uploaded. We show an alternative chained version (line 2) of the commands here to instantiate the BQSession and login at the same time. bq.init_local(user, pwd, bisque_root=root) # bq = BQSession().init_local(user, pwd, bisque_root=root) Inputs If you do not have an account on BisQue, make an account here. USER BisQue Username PASSWORD BisQue Password bisque_root “https://bisque.ece.ucsb.edu” Example. bq.init_local(user=amil_khan, pass=bisque1234, bisque_root=&quot;https://bisque.ece.ucsb.edu&quot;) Step 4. Instantiate the table service Now we need to instantiate the table service. To do this, use service to call the table service. Simple, right? table_service = bq.service (&#39;table&#39;) Step 5. Using the Table Service In this example, we use the load_array function from the table service to return a numpy array from the respective HDF file on BisQue. What is most important is the input to this function, which is as follows: data_array = table_service.load_array(table_uniq, path, slices=[]) Inputs table_uniq: BisQue URI (Required) path : Path to table within HDF (Required) slices : Slice of an array (Optional) What is the table_uniq The table_uniq argument comes from how BisQue handles resources. Let’s say you upload an image of a cat. BisQue will automatically assign a unique ID or, URI, to that image. Here is an example image: https://bisque.ece.ucsb.edu/client_service/view?resource=https://bisque.ece.ucsb.edu/data_service/00-s5b358UmuziTaUqqYtTcPF The last portion of the url is the URI. This is what you need to use as the input to the table_uniq argument. https://bisque.ece.ucsb.edu/data_service/00-s5b358UmuziTaUqqYtTcPF ^-----------------------^ COPY TABLE URI What is the path Say we have an array stored in a specific path in our HDF file. We can define a variable named table_path and place that after the table_uniq argument. Example table_path = &#39;PATH/TO/ARRAY/IN/HDF&#39; table_service.load_array(uri, table_path) Example. Functionalizing the Boring Stuff: get_table Here we provide a full working example of how to functionalize the entire process. Overall, the structure is the same as the sum of its pieces, but now we can import many arrays into, say, our Jupyter Notebook for simple data processing tasks. You can also extend this example to upload the table back to BisQue once the data preprocessing is done. def get_table(user,pwd, table_PATH, uri=None,root=&#39;https://bisque.ece.ucsb.edu&#39;): log = logging.getLogger(&#39;get_table&#39;) print(&quot;Starting Session...&quot;) bq = BQSession().init_local(user, pwd, bisque_root=root) print(&quot;BQSession Established. Attempting to fetch data...&quot;) table_service = bq.service (&#39;table&#39;) print(&quot;Successfully Retrieved Array!&quot;) logging.basicConfig() return table_service.load_array(uri, table_PATH) Let’s run our function! In this example, we are using the BQAPI to access an HDF file that contains a two-phase 3D microstructure. ms = get_table(amil_khan, bisque1234, &#39;DataContainers/ImageDataContainer/CellData/Phases&#39;, &#39;00-orJQLiXgqh8K955C6qzhyC&#39;) print(&#39;\\nShape of table: {}&#39;.format(ms.shape)) Output: Starting Session... BQSession Established. Attempting to fetch data... Successfully Retrieved Array! Shape of table: (5, 5, 5, 1) "],
["bisque-development.html", "4 BisQue Development", " 4 BisQue Development This guide details the installation of a bisque server on an Ubuntu 16.04 LTS environment. Project Source Github: https://github.com/UCSB-VRL/bisque Developer Installation Bisque Github Pages: https://ucsb-vrl.github.io/bisque-dev/guides/bisque Reference Bique Bioimage Google Groups Instructions on installing bisque using docker "],
["source-code-installation.html", "4.1 Source Code Installation", " 4.1 Source Code Installation NOTE: The source code installation has only been tested on Ubuntu 16.04. Pre-requisites sudo apt-get install -y python python-dev python-virtualenv python-numpy python-scipy sudo apt-get install -y libxml2-dev libxslt1-dev libhdf5-dev sudo apt-get install -y libmysqlclient-dev libpq-dev mercurial git cmake sudo apt-get install -y postgresql postgresql-client libsqlite3-dev sudo apt-get install -y python-paver python-setuptools sudo apt-get install -y graphviz libgraphviz-dev pkg-config sudo apt-get install -y openslide-tools python-openslide sudo apt-get install -y libfftw3-dev libbz2-dev libz-dev sudo apt-get install -y liblcms2-dev libtiff-dev libpng-dev sudo apt-get install -y libgdcm2.6 libopenslide-dev libopenslide0 Install Openjpeg git clone https://github.com/uclouvain/openjpeg cd openjpeg &amp;&amp; mkdir build &amp;&amp; cd build cmake .. -DCMAKE_BUILD_TYPE=Release sudo make -j4 install sudo ldconfig Install BioImageConvert BioImageConvert Source Repository Prebuilt Binaries Repository Setup for pre-built binaries (below) # Ubuntu 18 version wget https://bitbucket.org/dimin/bioimageconvert/downloads/imgcnv_ubuntu18_2.5.0.tar.gz # Ubuntu 16 version wget https://bitbucket.org/dimin/bioimageconvert/downloads/imgcnv_ubuntu16_2.4.3.tar.gz tar -xvzf imgcnv_ubuntu16_2.4.3.tar.gz sudo cp imgcnv_ubuntu16_2.4.3/imgcnv /usr/local/bin/ sudo cp imgcnv_ubuntu16_2.4.3/libimgcnv.so.2.4.3 /usr/local/lib/ sudo ln -s /usr/local/lib/libimgcnv.so.2.4.3 /usr/local/lib/libimgcnv.so.2.4 sudo ln -s /usr/local/lib/libimgcnv.so.2.4 /usr/local/lib/libimgcnv.so.2 sudo ln -s /usr/local/lib/libimgcnv.so.2 /usr/local/lib/libimgcnv.so sudo ldconfig Alternately, Compile by source and Install (You are on your own here) hg clone --insecure http://biodev.ece.ucsb.edu/hg/imgcnv cd imgcnv &amp;&amp; make -j6 sudo make install Clone the repository and Prepare Virtual Environment We will clone the stable repository and work inside a python virtual environment for setup requirements. git clone https://github.com/UCSB-VRL/bisque.git bisque-stable Its always a good practive to use a virtualenv to develop projects sudo pip install virtualenvwrapper Edit ~/.bashrc and export the following variables In case of issues around virtualenvwrapper make sure the paths in the variables below exist # virtualenv and virtualenvwrapper export PATH=/usr/local/bin:$PATH export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python export VIRTUALENVWRAPPER_VIRTUALENV=/usr/local/bin/virtualenv source /usr/local/bin/virtualenvwrapper.sh Now load this using “source ~/.bashrc” Create a virtual envrionment “mkvirtualenv -p /usr/bin/python2 bqdev” Change environment “workon bqdev” __Deprecated Bootstrap Installer (Do Not Use this Script)_ _ $ mkdir bisque &amp;&amp; cd bisque $ wget http://biodev.ece.ucsb.edu/projects/bisquik/export/tip/bisque-stable/contrib/bootstrap/bisque-bootstrap.py $ python bisque-bootstrap.py bqenv # Activate Virtualenv bisque$ source bqenv/bin/activate Now Install requirements pip install -i https://biodev.ece.ucsb.edu/py/bisque/xenial/+simple/ -r requirements.txt Alternate Index Url for Development: https://biodev.ece.ucsb.edu/py/bisque/dev/+simple Index Url Debian Stretch: https://biodev.ece.ucsb.edu/py/bisque/stretch/+simple/ Index Url Ubuntu xenial: https://biodev.ece.ucsb.edu/py/bisque/xenial/+simple/ Fix the requirements.txt (Only if the installation fails) #Fix the requirements.txt file using sed -i &#39;s/.*psycopg2==2.6.1.*/psycopg2==2.7.1./&#39; requirements.txt psycopg2==2.7.1 Minimatic==1.0 Paste==1.7.5.1 httplib2==0.7.3 #tgext.registration==0.1dev # Install separately since packages may be deprecated in PyPi easy_install http://biodev.ece.ucsb.edu/binaries/depot/tgext.registration2/tgext.registration2-0.5.2.tar.gz Configure Bisque Environment Run the Paver setup $ paver setup Expected paver log tail Installing collected packages: bqengine Running setup.py develop for bqengine Successfully installed bqengine Now run: bq-admin setup Run the bq-admin standalone setup $ bq-admin setup Expected bq-admin setup log tail (also observe the various inputs in the log for this setup) (bqdev) rahul@loup:~/repository/github/bisque$ bq-admin setup INFO:root:Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt INFO:root:Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt Developer installation DIRS: {&#39;bin&#39;: &#39;/home/rahul/.virtualenvs/bqdev/bin&#39;, &#39;run&#39;: &#39;.&#39;, &#39;share&#39;: &#39;.&#39;, &#39;plugins&#39;: &#39;./plugins&#39;, &#39;packages&#39;: &#39;/home/rahul/.virtualenvs/bqdev/lib/python2.7/site-packages&#39;, &#39;data&#39;: &#39;./data&#39;, &#39;virtualenv&#39;: &#39;/home/rahul/.virtualenvs/bqdev&#39;, &#39;default&#39;: &#39;./config-defaults&#39;, &#39;jslocation&#39;: &#39;bqcore&#39;, &#39;modules&#39;: &#39;./modules&#39;, &#39;depot&#39;: &#39;./external&#39;, &#39;config&#39;: &#39;./config&#39;, &#39;public&#39;: &#39;./public&#39;} INFO:root:Generating grammar tables from /usr/lib/python2.7/lib2to3/Grammar.txt INFO:root:Generating grammar tables from /usr/lib/python2.7/lib2to3/PatternGrammar.txt Developer installation DIRS: {&#39;bin&#39;: &#39;/home/rahul/.virtualenvs/bqdev/bin&#39;, &#39;run&#39;: &#39;.&#39;, &#39;share&#39;: &#39;.&#39;, &#39;plugins&#39;: &#39;./plugins&#39;, &#39;packages&#39;: &#39;/home/rahul/.virtualenvs/bqdev/lib/python2.7/site-packages&#39;, &#39;data&#39;: &#39;./data&#39;, &#39;virtualenv&#39;: &#39;/home/rahul/.virtualenvs/bqdev&#39;, &#39;default&#39;: &#39;./config-defaults&#39;, &#39;jslocation&#39;: &#39;bqcore&#39;, &#39;modules&#39;: &#39;./modules&#39;, &#39;depot&#39;: &#39;./external&#39;, &#39;config&#39;: &#39;./config&#39;, &#39;public&#39;: &#39;./public&#39;} This is the main installer for Bisque The system will initialize and be ready for use after a succesfull setup has completed. Several questions must be answered to complete the install. Each question is presented with default in brackets []. Pressing &lt;enter&gt; means that you are accepting the default value. You may request more information by responding with single &#39;?&#39; and then &lt;enter&gt;. For example: What is postal abbreviation of Alaska [AK]? The default answer is AK and is chosen by simply entering &lt;enter&gt; Beginning install of [&#39;bisque&#39;, &#39;engine&#39;] with [&#39;server&#39;] CALLING &lt;function install_external_binaries at 0x7f9533ffac08&gt; Fetch external binary files from Bisque development server [Y]? Y Matched section Linux-64bit-* extjs.zip found locally bioformats-pack.zip found locally libmbgl-linux-64-large.a found locally feature_extractors.zip found locally ImarisConvert.tar.gz found locally opencv-2.4.6.zip found locally CALLING &lt;function install_dependencies at 0x7f9533ffad70&gt; 2.4.3 Found imgcnv version 2.4.3 Imgcnv is installed and no-precompiled version exists. Using installed version ImarisConvert is up to date No pre-compiled version of openslide exists for your system Please visit our mailing list https://groups.google.com/forum/#!forum/bisque-bioimage for help Bioformats is up to date CALLING &lt;function install_features at 0x7f9533ffb050&gt; Install feature extractors (Feature Server) [Y]? Unpacking ./external/feature_extractors.zip into ./bqfeature/bq Install source code for feature extractors [N]? To enable the feature service to read OME-bigtiff for feature extraction install libtiff4 For Debian use the command apt-get install libtiff5-dev Install OpenCV-2.4.6 [Y]? Extracted opencv-2.4.6/python2.7/cv.py -&gt; /home/rahul/.virtualenvs/bqdev/lib/python2.7/site-packages/cv.py Extracted opencv-2.4.6/python2.7/cv2.so -&gt; /home/rahul/.virtualenvs/bqdev/lib/python2.7/site-packages/cv2.so CALLING &lt;function install_plugins at 0x7f9533ff9b18&gt; Try to install plugins [Y]? INFO &#39;svn&#39;not found: cannot fetch source repositories with svn INSTALL PLGINS [&#39;./plugins&#39;] Checking ./plugins for modules CALLING &lt;function install_public_static at 0x7f9533ffa848&gt; Deploy all static resources to public directory [Y]? Creating ./public INFO:bq.image_service.server:Available converters: openslide (1.1.1), imgcnv (2.4.3), ImarisConvert (8.0.2), bioformats (5.1.1) Problem loading registration = bq.registration.controllers.registration_service: &#39;User&#39; Generating packaged JS and CSS files INFO:minimatic:Combined -&gt; ./public/core/css/all_css.css: INFO:minimatic:Combined -&gt; ./public/core/js/all_js.js: CALLING &lt;function install_server_defaults at 0x7f9533ffa410&gt; Server config Top level site variables are: bisque.admin_email=YourEmail@YourOrganization bisque.admin_id=admin bisque.organization=Your Organization bisque.paths.root=. bisque.server=http://0.0.0.0:8088 bisque.title=Image Repository Change a site variable [N]? Y Enter the root URL of the server [http://0.0.0.0:8088]? http://loup.ece.ucsb.edu:8080 Your real name administrator account []? A login ID for the administrator account [admin]? An email for the administrator [YourEmail@YourOrganization]? A small organization title for the main page [Your Organization]? The main title for the web page header [Image Repository]? Installation Directory [.]? Do you want to create new server configuations [Y]? {&#39;backend&#39;: &#39;paster&#39;, &#39;e1.bisque.has_database&#39;: &#39;false&#39;, &#39;e1.bisque.static_files&#39;: &#39;false&#39;, &#39;e1.services_enabled&#39;: &#39;engine_service&#39;, &#39;e1.url&#39;: &#39;http://0.0.0.0:27000&#39;, &#39;h1.bisque.static_files&#39;: &#39;true&#39;, &#39;h1.services_disabled&#39;: &#39;&#39;, &#39;h1.services_enabled&#39;: &#39;&#39;, &#39;h1.url&#39;: &#39;http://0.0.0.0:8088&#39;, &#39;servers&#39;: &#39;h1&#39;} The server agent for bisque [paster]? list of server entries to be configured [h1]? Install (update) paster configs (application server and configs) [Y]? PARAMS {&#39;h1.bisque.static_files&#39;: &#39;true&#39;, &#39;h1.services_enabled&#39;: &#39;&#39;, &#39;e1.bisque.has_database&#39;: &#39;false&#39;, &#39;h1.url&#39;: &#39;http://0.0.0.0:8088&#39;, &#39;servers&#39;: &#39;h1&#39;, &#39;h1.services_disabled&#39;: &#39;&#39;, &#39;e1.url&#39;: &#39;http://0.0.0.0:27000&#39;, &#39;e1.bisque.static_files&#39;: &#39;false&#39;, &#39;e1.services_enabled&#39;: &#39;engine_service&#39;, &#39;backend&#39;: &#39;paster&#39;} h1: the url of the server [http://0.0.0.0:8088]? http://loup.ece.ucsb.edu:8080 h1: Services enabled []? h1: Services disabled []? Created paster config: ./config/h1_paster.cfg CALLING &lt;function install_mail at 0x7f9533ffa758&gt; Enable mail delivery [Y]? N CALLING &lt;function install_secrets at 0x7f9533ffa8c0&gt; Encrypt cookies with secret phrase [CEMWOJ65]? CALLING &lt;function install_database at 0x7f9533ff9578&gt; A database URI [sqlite:///data/bisque.db]? Trying to import driver sqlite3... Driver successfully imported. Create and initialize database [Y]? A database URI [sqlite:///data/bisque.db]? Checking whether database &quot;data/bisque.db&quot; already exists... Yes, it exists. Upgrading database version (alembic) INFO [alembic.migration] Context impl SQLiteImpl. INFO [alembic.migration] Will assume non-transactional DDL. CALLING &lt;function install_preferences at 0x7f9533ffa7d0&gt; Initialize Preferences [Y]? Force initialization [N]? INFO:bq.config:DATABASE sqlite:///data/bisque.db INFO:bq.config:SQLLite special handling NullPool timoout INFO:bq.image_service.server:Available converters: openslide (1.1.1), imgcnv (2.4.3), ImarisConvert (8.0.2), bioformats (5.1.1) INFO:bq.blobs.mounts:Loaded drivers OrderedDict([(&#39;local&#39;, {&#39;top&#39;: &#39;file://$datadir/imagedir/&#39;, &#39;mounturl&#39;: &#39;file://$datadir/imagedir/$user/&#39;})]) WARNING:bq.blobs.mounts:SQLITE does not support subtransactions: some mount service operations will fail INFO:bq.blobs.plugins:Resource plugins: [&#39;(bisque_pipeline, bq)&#39;, &#39;(cellprofiler_pipeline, cppipe)&#39;, &#39;(cellprofiler_pipeline, cp)&#39;, &#39;(dream3d_pipeline, json)&#39;, &#39;(imagej_pipeline, ijm)&#39;, &#39;(text, asc)&#39;, &#39;(text, ascii)&#39;, &#39;(text, zw)&#39;, &#39;(text, hz)&#39;, &#39;(text, txt)&#39;, &#39;(text, utxt)&#39;, &#39;(text, utf8)&#39;, &#39;(table, csv)&#39;, &#39;(table, hdf)&#39;, &#39;(table, hdf5)&#39;, &#39;(table, h5)&#39;, &#39;(table, he5)&#39;, &#39;(table, h5ebsd)&#39;, &#39;(table, dream3d)&#39;, &#39;(table, csv)&#39;, &#39;(table, xls)&#39;, &#39;(table, xlsx)&#39;] WARNING:bq.service:Following service were not found: set([&#39;mnt&#39;]) /home/rahul/.virtualenvs/bqdev/local/lib/python2.7/site-packages/sqlalchemy/sql/sqltypes.py:226: SAWarning: Unicode type received non-unicode bind param value &#39;system&#39;. (this warning may be suppressed after 10 occurrences) (util.ellipses_string(value),)) NO ACTION: System object initialized at &lt;system created=&quot;2019-02-04T10:51:57.823907&quot; name=&quot;system&quot; owner=&quot;http://localhost/data_service/00-2jimYQLLjB3yy3HuTwQM5c&quot; permission=&quot;published&quot; resource_uniq=&quot;00-UAZfWJYjDKp4yhabV3PP7S&quot; ts=&quot;2019-02-04T10:51:57.823907&quot; uri=&quot;http://localhost/data_service/00-UAZfWJYjDKp4yhabV3PP7S&quot;/&gt; Problem initializing preferences.. please use bq-admin preferences Initialize your database with: $ bq-admin setup createdb You can start bisque with: $ bq-admin server start then point your browser to: http://loup.ece.ucsb.edu:8080 If you need to shutdown the servers, then use: $ bq-admin server stop You can login as admin and change the default password. Send Installation/Registration report [Y]? N (bqdev) rahul@loup:~/repository/github/bisque$ Add “config/runtime-bisque.cfg” for module configuration and docker image registry Edit and add run config from config-defaults/runtime-bisque.defaults to config/runtime-bisque.cfg Here are some local changes but requires docker to be setup runtime.platforms = command runtime.staging_base = staging/ [docker] docker.enabled = true # A hub where to push containers to docker.hub = biodev.ece.ucsb.edu:5000 Run Bisque Server Start/Stop the server $ bq-admin server start $ bq-admin server stop Overview of Installation (Just for review) workon bqdev paver setup [server|engine] bq-admin setup [server|engine] bq-admin deploy public Open in browser Upload Dataset Upload an image file from your local directory to Bisque Browse uploaded dataset in the file explorer Select Browse menu item in the navigation bar and click on dataset Thereafter click on the files tab and click through the local database folder in the left document tree section. Upload Image file Select the uploaded file to view This visualization is by default 2D in nature. The various slices can be stepped through or played using the scroll bar on righ bottom of the image view area View 2D Image file A 3D visualization can be explored by clicking the cube icon towards the right of share and delete icons on the tool bar right below the navigation bar. View 3D Image file Module Load/Install Module packages and dependencies Lets take module/MetaData code as an example. Ensure ~/bisque/config/runtime-bisque.cfg has the configuration as below runtime.staging_base = staging/ docker.hub = biodev.ece.ucsb.edu:5000 Make sure the runtime-module.cfg is as per below module_enabled = True runtime.platforms=command [command] environments = Staged executable = python MetaData.py files = MetaData.py Now build/compile this module cd ~/bisque/modules/MetaData python setup.py Open up the Bisque web interface at http://loup.ece.ucsb.edu:8088 Login using admin:admin Update the email address in the users context menu item (This is important) Open Module Manager from the admin user context menu Paste the following URL in the Module-&gt;Engine Module http://loup.ece.ucsb.edu:8088/engine_service/ List of engine modules could be seen Drag-n-Drop say MetaData module from the list to the left window and close the window Debug Module Every module run will generate a model execution identifier to track this execution. You can observe this after clicking the run command and you have a result. It could be success or fail in the Results section http://loup.ece.ucsb.edu:8088/module_service/MetaData/?wpublic=1#mex=http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF The mex identifier (==MEX_ID=00-ZmuAoE43wTxByycmaCnvBF==) observed from URL can be used to locate this execution code &amp; resulting logs in the staging folders change directory to this staging folder and observe the files there cd ~/bisque/staging/00-ZmuAoE43wTxByycmaCnvBF rahul@loup:~/bisque/staging/00-ZmuAoE43wTxByycmaCnvBF$ tree . ├── MetaData.log ├── MetaData.py ├── python.log └── state00-ZmuAoE43wTxByycmaCnvBF.bq 0 directories, 4 files Here we can see that the MetaData.log and python.log files are generated In case of issues these are the log files that we need to look into for detailed error reporting main log file is the bisque_8088.log file at the ~/bisque home directory 13:45:11,996 INFO [bq.root] [admin] POST http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF?view=short 13:45:12,001 INFO [bq.module_server] MEX APPEND http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF?view=short 13:45:12,205 INFO [bq.engine_service.command_run] SUCCESS Command python MetaData.py http://loup.ece.ucsb.edu:8088/data_service/00-6dpWgEAue2iz8YZcKPHejh http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF admin:00-ZmuAoE43wTxByycmaCnvBF with 0 13:45:12,206 INFO [bq.engine_service.command_run] All processes have returned [&#39;finished&#39;] 13:45:12,206 INFO [bq.engine_service.command_run] finishing 1 mexes -&gt; [{&#39;files&#39;: [&#39;MetaData.py&#39;], &#39;status&#39;: &#39;finished&#39;, &#39;executable&#39;: [&#39;python&#39;, &#39;MetaData.py&#39;, &#39;http://loup.ece.ucsb.edu:8088/data_service/00-6dpWgEAue2iz8YZcKPHejh&#39;, &#39;http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;admin:00-ZmuAoE43wTxByycmaCnvBF&#39;], &#39;initial_dir&#39;: &#39;/home/rahul/repository/github/bisque-dev&#39;, &#39;module_enabled&#39;: &#39;True&#39;, &#39;named_args&#39;: {&#39;bisque_token&#39;: &#39;admin:00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;image_url&#39;: &#39;http://loup.ece.ucsb.edu:8088/data_service/00-6dpWgEAue2iz8YZcKPHejh&#39;, &#39;mex_url&#39;: &#39;http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF&#39;}, &#39;bisque_token&#39;: u&#39;admin:00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;environments&#39;: &#39;Staged&#39;, &#39;runtime.staging_base&#39;: &#39;staging/&#39;, &#39;mex_id&#39;: &#39;00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;runtime.matlab_launcher&#39;: &#39;config-defaults/templates/matlab_launcher_SYS.tmpl&#39;, &#39;arguments&#39;: [], &#39;module_dir&#39;: &#39;/home/rahul/repository/github/bisque-dev&#39;, &#39;staging_path&#39;: &#39;/home/rahul/repository/github/bisque-dev/staging/00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;iterables&#39;: False, &#39;log_name&#39;: &#39;/home/rahul/repository/github/bisque-dev/staging/00-ZmuAoE43wTxByycmaCnvBF/python.log&#39;, &#39;runtime.matlab_home&#39;: &#39;&#39;, &#39;mex_url&#39;: &#39;http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;rundir&#39;: &#39;/home/rahul/repository/github/bisque-dev/staging/00-ZmuAoE43wTxByycmaCnvBF&#39;, &#39;runtime.platforms&#39;: &#39;command&#39;}] This will show us the COMMAND that was run to execute this module with MEX_URL python MetaData.py \\ http://loup.ece.ucsb.edu:8088/data_service/00-6dpWgEAue2iz8YZcKPHejh \\ http://loup.ece.ucsb.edu:8088/module_service/mex/00-ZmuAoE43wTxByycmaCnvBF \\ admin:00-ZmuAoE43wTxByycmaCnvBF This is the command that we can use to debug and rerun/replay this MEX in order to update the execution result. This is different from running the module again from the web interface since that will produce a new MEX_ID and create another staging folder corresponding to that. G. Module MEX/UI Click on Browse-&gt;mex to go to the Model execution page Mex Module Mex Browse Here we will be able to see the various MEX sessions that were run for all modules under execution We will be able to obtain the MEX_ID and view its state from here by selecting one of the executions of interest. Mex Success Module In case we select a module that has errors in it then it would turn out to show the status with messages in red Mex Success Module Now let us go to Browse-&gt;dataset and select the file that we ran the module for. Here we will be able to view the Annotation that was added by the Metadata module to this image. Annotation can be visualized using the “Annotations” tab on the right Data Annot Module The Model execution runs can be seen in the “Analysis” tab on the right Data Mex Module Further Docker &amp; Condor based modules require additional setup Install Docker (https://docs.docker.com/install/linux/docker-ce/ubuntu/) Also go through the post-installation steps Also install the Nvidia-docker in case you are planning to use GPU based modules or connoisseur services. Install Condor (https://research.cs.wisc.edu/htcondor/ubuntu/) Understand the configurations as well for master &amp; slave setup Bisque Condor Setup Instructions rahul@bqdev:~$ /etc/init.d/condor restart [ ok ] Restarting condor (via systemctl): condor.service. rahul@bqdev:~$ ps -ef | grep condor "],
["planteome-deep-segment.html", "4.2 Planteome Deep Segment", " 4.2 Planteome Deep Segment This module segments a marked object (creating a graphical object) within an input image. Then the module will classify either the entire original image or the segment created in the first step. This uses PyTorch in order to do this deep segmentation. 4.2.0.1 Reference Module Development Guide: https://github.com/pndaly/BisQue_Platform_Guide Sample Deep Learning Module: Planteome Deep Segment Analysis 4.2.0.2 Prerequisites Working bisque environment at http://loup.ece.ucsb.edu:8088/ Docker should be enabled and setup on this environment The bisque deployment server should have access to good CPU &amp; RAM since Torch &amp; Scikit-image is used Access to module folder for deploying this module (Say at ~/bisque/module) 4.2.0.3 Add/Deploy the Planteome module Identify the bisque module folder at path ~/bisque/module Login to http://loup.ece.ucsb.edu:8088/ with credentials admin:admin Download the Planteome module to the bisque module folder Register the module to Bisque by opening the Module Manager Provide the engine URL(http://loup.ece.ucsb.edu:8088/engine_service) in the Engine service section and click load. This will list the modules by querying the engine service. Select the module named “Planteome”, drag this module to the left pane and drop it to register. 4.2.0.4 Build/Configure the module Edit the runtime-module.cfg with relevant configuration Changed the docker.hub configuration to biodev.ece.ucsb.edu:5000 View/Edit the Dockerfile for the relevant packages Edited versions for numpy==1.16.1 &amp; scikit-image==0.14.2 Source to your bisque python environment “workon bqenv” for installation pip install -r requirements.txt python setup.py This will install all the dependency in the modules requirements.txt file, build modules code, and create a docker image for running it. Based on your “docker.hub” configuration the setup will push the docker image to registry as [biodev.ece.ucsb.edu:5000/bisque_uplanteome] 4.2.0.5 Steps to run the algorithm from Bisque Client Select an image to be analyzed. The foreground/background annotation tooltip can be found on the top-right of the module image viewer. Mark the part of the image to be segmented with foreground line(s) annotation(s). Mark the image with background annotations around the object to be segmented. Select which deep classifier to use, whether to segment the image, the segmentation quality, and whether to classify the entire image or the segmented object instead. Press the ‘RUN’ button. Analysis may take some time depending on the image and segmentation quality. Results are given in visual and table formats, depending on whether the segmentation and classification functionalities respectively were enabled in the options. 4.2.0.6 Isolated/Development test setup Make sure you have annotated the image and have an a mex identifier availablefor manual test/run. This can be done by, - Opening the module and select image - Annotate the image as per the directions above - Configure and run the module once - Make note of the mex URL for this run by looking at the docker_run.log in the staging folder. This will be used for replaying the test run from the modules folder. Additional module execution information - When we annotate the image and click RUN on the module user interface - The Planteome module is created from biodev.ece.ucsb.edu:5000/bisque_uplanteome:latest ``` docker create biodev.ece.ucsb.edu:5000/bisque_uplanteome \\ python PlanteomeDeepSegment.py \\ http://loup.ece.ucsb.edu:8088/module_service/mex/00-NKpU4CWiHfupgckuXBNFDd \\ admin:00-NKpU4CWiHfupgckuXBNFDd Simple True 3 False ``` This module is run with the hash id of the docker create 4.2.0.6.1 Setup/Run the docker container for test Build the docker container docker build –no-cache -t bisque_uplanteome -f Dockerfile . docker build -t biodev.ece.ucsb.edu:5000/bisque_uplanteome . Run the container and bash into it docker run -it –net=host biodev.ece.ucsb.edu:5000/bisque_uplanteome bash test run the code on mex identifier python PlanteomeDeepSegment.py http://loup.ece.ucsb.edu:8088/module_service/mex/00-NKpU4CWiHfupgckuXBNFDd admin:00-NKpU4CWiHfupgckuXBNFDd Simple True 3 False Version: 0.3 Author(s): Dimitrios Trigkakis, Justin Preece "],
["rancher-2-0-setup-wkubernetes-engine.html", "4.3 Rancher 2.0 Setup (w/Kubernetes engine)", " 4.3 Rancher 2.0 Setup (w/Kubernetes engine) 4.3.1 Pre-requisite Rancher 2.0 with bq-cluster workload instructions Rancher 2.0 with PostgreSql workload instructions 4.3.1.0.1 General instructions Setup Cluster with /rke-clusters/custom-nodes 4.3.1.0.2 Note: Assuming we have bq-cluster with postgres and persistent volumes 4.3.2 Setup Workload on the bq-cluster Bisque Test environment where workloads are deployed with open NodePort https://rancher.com/managing-kubernetes-workloads-with-rancher-2-0/ We will be using the image at custom registry biodev.ece.ucsb.edu:5000/ucsb-bisque05-svc or another available at vishwakarmarhl/ucsb-bisque05-svc:dev 4.3.2.0.1 Bisque Service Workload configuration Name: ucsb-bisque05-svc Pods: 2 Docker Image : biodev.ece.ucsb.edu:5000/bisque-caffe-xenial:dev or vishwakarmarhl/ucsb-bisque05-svc:dev Port Mapping: 8080-tcp-NodePort-Random &amp; 27000-tcp-NodePort-Random Environment Variables: Copy paste the “Environment Configuration” section Node Scheduling: Run all the pods on a particular host Health Check: No change Volumes: Persistent Volume claim and set the mount point as /run/bisque Scaling: No change Command: No Change Networking: No Change Labels: No change Security: No change 4.3.2.0.2 Environment Configuration Bisque service variables BISQUE_USER= bisque BISQUE_BISQUE_ADMIN_EMAIL= admin@loup.ece.ucsb.edu BISQUE_BISQUE_BLOB_SERVICE_STORES= blobs,local BISQUE_BISQUE_STORES_BLOBS_MOUNTURL= file://$$datadir/blobdir/$$user/ BISQUE_BISQUE_STORES_BLOBS_TOP= file://$$datadir/blobdir/ BISQUE_BISQUE_STORES_LOCAL_MOUNTURL= file://$$datadir/imagedir/$$user/ BISQUE_BISQUE_STORES_LOCAL_READONLY= true BISQUE_BISQUE_STORES_LOCAL_TOP= file://$$datadir/imagedir/ BISQUE_DOCKER_DOCKER_HUB= biodev.ece.ucsb.edu:5000 BISQUE_SECRET= bq123 BISQUE_UID= 12027 BISQUE_RUNTIME_STAGING_BASE= /run/bisque/data/staging BQ__BISQUE__IMAGE_SERVICE__WORK_DIR= /run/bisque/local/workdir BQ__BISQUE__PATHS__DATA= /run/bisque/data MAIL_SERVER= dough.ece.ucsb.edu BISQUE_DBURL=postgresql://postgres:postgres@10.42.0.15:5432/postgres DEBIAN_FRONTEND=noninteractive IMGCNV=imgcnv_ubuntu16_2.4.3 4.3.2.0.3 Condor provisioning Condor Master - Image: biodev.ece.ucsb.edu:5000/condor - Ports: 9618, 9886 as HostPort - Environment CONDOR_DAEMONS = COLLECTOR,MASTER,NEGOTIATOR,SCHEDD,SHARED_PORT CONDOR_MANAGER_HOST = master Condor Worker - Same configuration as above - Ports: 9886 NodePort Random 4.3.2.0.4 Workload (bq-cluster) Dashboard Rancher Workload Dashboard "],
["connoisseurgpu-workload-provisioning.html", "4.4 Connoisseur/GPU Workload provisioning", " 4.4 Connoisseur/GPU Workload provisioning Here lets take a look at connoissuer service in Bisque. We will run a Bisque H1 server disabling the engine_service and connoisseur in part (A) and later another service in part (B) with Connoisseur and engine service for the actual compute. 4.4.0.0.1 Pre-requisites Create a namespace “connoisseur” and deploy everything isolated from the existing bisque-svc Create a postgres database for this deployment psql -h 10.42.0.15 -U postgres –password -p 5432 postgres “create database connoissuer;” “grant all privileges on database connoisseur to postgres;” Create a volume bqcon-vol mounted at 192.168.1.123:/opt/bisque/connoisseur over NFS 4.4.0.1 A.) Bisque Client Service Workload configuration Name: bq-connoisseur-client-svc Pods: 1 Docker Image : biodev.ece.ucsb.edu:5000/bisque-caffe-xenial:dev Port Mapping: 80-tcp-NodePort-Random &amp; 27000-tcp-NodePort-Random Environment Variables: Copy paste the “Environment Configuration” section Node Scheduling: Run all the pods on a particular host that has GPU, Say “arkady” Health Check: No change Volumes: Persistent Volume claim of bqcon-vol and set the mount point as /run/bisque/ Scaling: No change Command: No Change Networking: No Change Labels: No change Security: No change 4.4.0.1.1 Environment Configuration Bisque client service variables BISQUE_USER= bisque BISQUE_BISQUE_ADMIN_EMAIL= admin@loup.ece.ucsb.edu BISQUE_BISQUE_BLOB_SERVICE_STORES= blobs,local BISQUE_BISQUE_STORES_BLOBS_MOUNTURL= file://$$datadir/blobdir/$$user/ BISQUE_BISQUE_STORES_BLOBS_TOP= file://$$datadir/blobdir/ BISQUE_BISQUE_STORES_LOCAL_MOUNTURL= file://$$datadir/imagedir/$$user/ BISQUE_BISQUE_STORES_LOCAL_READONLY= true BISQUE_BISQUE_STORES_LOCAL_TOP= file://$$datadir/imagedir/ BISQUE_DOCKER_DOCKER_HUB= biodev.ece.ucsb.edu:5000 BISQUE_SECRET= bq123 BISQUE_UID= 12027 BISQUE_RUNTIME_STAGING_BASE= /run/bisque/data/staging BQ__BISQUE__IMAGE_SERVICE__WORK_DIR= /run/bisque/local/workdir BQ__BISQUE__PATHS__DATA= /run/bisque/data MAIL_SERVER= dough.ece.ucsb.edu DEBIAN_FRONTEND=noninteractive IMGCNV=imgcnv_ubuntu16_2.4.3 BISQUE_DBURL=postgresql://postgres:postgres@10.42.0.15:5432/connoisseur BISQUE_SERVERS_H1_SERVICES_DISABLED = engine_service,connoisseur 4.4.0.2 B.) Bisque Engine Service Workload configuration All the same configuration as above but skipping one environment variable Skip the disable variable –&gt; BISQUE_SERVERS_H1_SERVICES_DISABLED = engine_service,connoisseur Verify connoisseur GPU variables NVIDIA_REQUIRE_CUDA=cuda&gt;=8.0 NVIDIA_VISIBLE_DEVICES=all NVIDIA_DRIVER_CAPABILITIES=compute,utility CUDA_PKG_VERSION=8-0=8.0.61-1 CAFFE_PKG_VERSION=0.15.13-1ubuntu16.04+cuda8.0 CAFFE_VERSION=0.15 CUDA_VERSION=8.0.61 CONDOR_MANAGER_HOST=master.condor CONDOR_DAEMONS=MASTER,SCHEDD,SHARED_PORT 4.4.0.2.1 Workload (bq-cluster) with Namespace Connoisseur Rancher Workload Dashboard TODO: - Fix Caffe and CUDA within the image - Probably write your own Docker file for a new CUDA/GPU enabled container bisque@bq-connoisseur-engine-svc-74755f798b-6lbgk:/source$ caffe deveice_query -gpu all E0213 00:36:24.855478 1798 caffe.cpp:77] Available caffe actions: E0213 00:36:24.856573 1798 caffe.cpp:80] device_query E0213 00:36:24.856690 1798 caffe.cpp:80] test E0213 00:36:24.856793 1798 caffe.cpp:80] time E0213 00:36:24.856899 1798 caffe.cpp:80] train F0213 00:36:24.857019 1798 caffe.cpp:82] Unknown action: deveice_query *** Check failure stack trace: *** @ 0x7fafbc7c65cd google::LogMessage::Fail() @ 0x7fafbc7c8433 google::LogMessage::SendToLog() @ 0x7fafbc7c615b google::LogMessage::Flush() @ 0x7fafbc7c8e1e google::LogMessageFatal::~LogMessageFatal() @ 0x40863a main @ 0x7fafbb218830 __libc_start_main @ 0x408dd9 _start @ (nil) (unknown) Aborted (core dumped) "],
["rancher-condor.html", "4.5 Rancher Condor", " 4.5 Rancher Condor The Condor instructions are based out of custom image(biodev.ece.ucsb.edu:5000/condor) Official Docs: https://research.cs.wisc.edu/htcondor/manual/v8.8 4.5.1 Topology The condor image available at the registry has htcondor==8.4.2~dfsg.1-1build1 pre-installed. Submit Node (host = bisquesvc.prod) Master node (host = master.condor) Worker Nodes (host = worker*.condor) Docker typically runs at worker and on the Bisque submit node for cases where we dont use condor at all Test this using docker ps on the worker nodes Now on each node we should start Condor and also make sure that the hostname “master.condor” is reachable from all the nodes in the pool, including the bisque submit node. $ ping master.condor PING master.condor.svc.cluster.local (10.43.55.33) 56(84) bytes of data. $ service condor start 4.5.2 Master/Worker Condor Config 4.5.2.1 Initiate startd at master and workers condor_startd 4.5.2.2 Condor config vim /etc/condor/condor_config.local Add the following in the section where you see ALLOW_READ/WRITE keys ALLOW_ADMINISTRATOR = $(CONDOR_HOST) ALLOW_OWNER = $(FULL_HOSTNAME), $(ALLOW_ADMINISTRATOR) ALLOW_READ = * ALLOW_WRITE = * ALLOW_NEGOTIATOR = * ALLOW_NEGOTIATOR_SCHEDD = * ALLOW_WRITE_COLLECTOR = $(ALLOW_WRITE), $(FLOCK_FROM) ALLOW_WRITE_STARTD = $(ALLOW_WRITE), $(FLOCK_FROM) ALLOW_READ_COLLECTOR = $(ALLOW_READ), $(FLOCK_FROM) ALLOW_READ_STARTD = $(ALLOW_READ), $(FLOCK_FROM) ALLOW_CLIENT = * ALLOW_ADVERTISE_STARTD = * SEC_DEFAULT_NEGOTIATION = NEVER SEC_DEFAULT_AUTHENTICATION = NEVER 4.5.2.3 Reconfig &amp; Restart Condor condor_reconfig service condor restart 4.5.3 BisqueSvc Submit Node Condor Config Here is contents of the production configuration /etc/condor/condor_config.local file CONDOR_HOST = master.condor COLLECTOR_NAME = CBIUCSB DAEMON_LIST = MASTER,SCHEDD,SHARED_PORT CONDOR_ADMIN = admin@biodev.ece.ucsb.edu ## Do you want to use NFS for file access instead of remote system calls ALLOW_READ = $(ALLOW_READ), 172.*, 10.*, 128.111.*, *.ece.ucsb.edu, *.cs.ucsb.edu ALLOW_WRITE = $(ALLOW_WRITE), 172.*, 10.*, 128.111.*, *.ece.ucsb.edu, *.cs.ucsb.edu ALLOW_NEGOTIATOR = 172.*, 10.*, 128.111.* #https://lists.cs.wisc.edu/archive/htcondor-users/2016-December/msg00046.shtml DISCARD_SESSION_KEYRING_ON_STARTUP = false # Use CCB with shared port so outside units can talk to USE_SHARED_PORT = TRUE SHARED_PORT_ARGS = -p 9886 UPDATE_COLLECTOR_WITH_TCP = TRUE BIND_ALL_INTERFACES = TRUE # Slots for multi-cpu machines NUM_SLOTS = 1 NUM_SLOTS_TYPE_1 = 1 SLOT_TYPE_1 = 100% SLOT_TYPE_1_PARTITIONABLE = true START = True PREEMPT = False SUSPEND = False KILL = False WANT_SUSPEND = False WANT_VACATE= False CONTINUE= True 4.5.4 State &amp; logs condor_status for the state of the pool root@bisquevc:/source# condor_status Name OpSys Arch State Activity LoadAv Mem ActvtyTime slot1@master-7b988 LINUX X86_64 Unclaimed Idle -1.000 64423 0+13:07:28 slot1@worker-6c6cc LINUX X86_64 Unclaimed Idle -1.000 64423 0+13:04:24 Total Owner Claimed Unclaimed Matched Preempting Backfill X86_64/LINUX 2 0 0 2 0 0 0 Total 2 0 0 2 0 0 0 condor_q for the schedule of the queue. You can use “-analyse” to get additional details on the jobs. root@bisquesvc:/source# condor_q -- Schedd: bisquesvc : &lt;10.42.0.15:40007&gt; ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 0 jobs; 0 completed, 0 removed, 0 idle, 0 running, 0 held, 0 suspended 4.5.5 Test Condor Condor is configured to be run as a user and not root. So we will change user (su bisque) to bisque and operate with a regular user level privileges for job submittion purposes. 4.5.5.0.1 Create a file dock.sh with the following commands #!/bin/bash echo &quot;Hello HTCondor from Job $1 running on `whoami`@`hostname`&quot; docker --version sleep 10s 4.5.5.0.2 Create a dock.submit file with the following paramaters executable = dock.sh arguments = $(Process) universe = vanilla output = dock_$(Cluster)_$(Process).out error= dock_$(Cluster)_$(Process).error log = dock_$(Cluster)_$(Process).log should_transfer_files = YES when_to_transfer_output = ON_EXIT queue 2 4.5.5.0.3 Now execute bisque@bisquesvc:~/condor_dock_test$ condor_submit dock.submit Submitting job(s).. 2 job(s) submitted to cluster 10. Here we also observe the status of condor queue which should have the jobs running bisque@bisquesvc:~/condor_dock_test$ condor_q -- Schedd: bisquesvc : &lt;10.42.0.15:9886?... ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 11.0 bisque 3/5 22:37 0+00:00:00 I 0 0.0 dock.sh 0 11.1 bisque 3/5 22:37 0+00:00:00 I 0 0.0 dock.sh 1 2 jobs; 0 completed, 0 removed, 2 idle, 0 running, 0 held, 0 suspended When the Master/worker nodes executes the job we see the following state bisque@bisquesvc:~/condor_dock_test$ condor_status Name OpSys Arch State Activity LoadAv Mem ActvtyTime slot1@master-7b988 LINUX X86_64 Unclaimed Idle 0.000 64295 0+00:00:04 slot1_1@master-7b9 LINUX X86_64 Claimed Busy -1.000 128 0+00:00:04 slot1@worker-6c6cc LINUX X86_64 Unclaimed Idle 0.000 64295 0+00:00:04 slot1_1@worker-6c6 LINUX X86_64 Claimed Busy -1.000 128 0+00:00:04 Total Owner Claimed Unclaimed Matched Preempting Backfill X86_64/LINUX 4 0 2 2 0 0 0 Total 4 0 2 2 0 0 0 In about 10 seconds this execution will terminate and dump the results in corresponding log files bisque@bisquesvc:~/condor_dock_test$ condor_status Name OpSys Arch State Activity LoadAv Mem ActvtyTime slot1@master-7b988 LINUX X86_64 Unclaimed Idle 0.000 64295 0+00:00:04 slot1@worker-6c6cc LINUX X86_64 Unclaimed Idle 0.000 64295 0+00:00:04 Total Owner Claimed Unclaimed Matched Preempting Backfill X86_64/LINUX 2 0 0 2 0 0 0 Total 2 0 0 2 0 0 0 bisque@bisquesvc:~/condor_dock_test$ condor_q -- Schedd: bisquesvc : &lt;10.42.0.15:9886?... ID OWNER SUBMITTED RUN_TIME ST PRI SIZE CMD 0 jobs; 0 completed, 0 removed, 0 idle, 0 running, 0 held, 0 suspended To verify the execution at worker/master we can take a look at the /var/log/condor/StartLog # Logs at the master condor node 03/05/19 22:37:54 slot1_1: Request accepted. 03/05/19 22:37:54 slot1_1: Remote owner is bisque@bisquesvc 03/05/19 22:37:54 slot1_1: State change: claiming protocol successful 03/05/19 22:37:54 slot1_1: Changing state: Owner -&gt; Claimed 03/05/19 22:37:54 slot1_1: Got activate_claim request from shadow (10.42.0.15) 03/05/19 22:37:54 /proc format unknown for kernel version 4.15.0 03/05/19 22:37:54 slot1_1: Remote job ID is 11.0 03/05/19 22:37:54 slot1_1: Got universe &quot;VANILLA&quot; (5) from request classad 03/05/19 22:37:54 slot1_1: State change: claim-activation protocol successful 03/05/19 22:37:54 slot1_1: Changing activity: Idle -&gt; Busy 03/05/19 22:37:59 /proc format unknown for kernel version 4.15.0 03/05/19 22:38:04 /proc format unknown for kernel version 4.15.0 03/05/19 22:38:09 /proc format unknown for kernel version 4.15.0 03/05/19 22:38:09 slot1_1: Called deactivate_claim_forcibly() 03/05/19 22:38:09 Starter pid 1141 exited with status 0 03/05/19 22:38:09 slot1_1: State change: starter exited 03/05/19 22:38:09 slot1_1: Changing activity: Busy -&gt; Idle 03/05/19 22:38:09 slot1_1: State change: received RELEASE_CLAIM command 03/05/19 22:38:09 slot1_1: Changing state and activity: Claimed/Idle -&gt; Preempting/Vacating 03/05/19 22:38:09 slot1_1: State change: No preempting claim, returning to owner 03/05/19 22:38:09 slot1_1: Changing state and activity: Preempting/Vacating -&gt; Owner/Idle 03/05/19 22:38:09 slot1_1: State change: IS_OWNER is false 03/05/19 22:38:09 slot1_1: Changing state: Owner -&gt; Unclaimed 03/05/19 22:38:09 slot1_1: Changing state: Unclaimed -&gt; Delete 03/05/19 22:38:09 slot1_1: Resource no longer needed, deleting Final results of the output could be seen in the dock_11_*.out result files which represents the Job Id = 11 bisque@bisquesvc:~/condor_dock_test$ ll total 36 drwxrwxr-x 2 bisque bisque 4096 Mar 5 22:37 ./ drwxr-xr-x 1 bisque bisque 4096 Mar 5 22:34 ../ -rw-r--r-- 1 bisque bisque 0 Mar 5 22:37 dock_11_0.error -rw-rw-r-- 1 bisque bisque 1021 Mar 5 22:38 dock_11_0.log -rw-r--r-- 1 bisque bisque 132 Mar 5 22:38 dock_11_0.out -rw-r--r-- 1 bisque bisque 0 Mar 5 22:37 dock_11_1.error -rw-rw-r-- 1 bisque bisque 1021 Mar 5 22:38 dock_11_1.log -rw-r--r-- 1 bisque bisque 132 Mar 5 22:38 dock_11_1.out -rw-r--r-- 1 bisque bisque 163 Mar 5 22:34 dock.sh -rw-r--r-- 1 bisque bisque 253 Mar 5 09:07 dock.submit Output Result bisque@bisquesvc:~/condor_dock_test$ cat dock_11_1.out Hello HTCondor from Job 1 running on nobody@master-7b988ddb7d-hnspj Docker version 17.03.0-ce, build 60ccb22 Completed my first job Output Log bisque@bisquesvc:~/condor_dock_test$ cat dock_11_1.log 000 (011.001.000) 03/05 22:37:44 Job submitted from host: &lt;10.42.0.15:9886?addrs=10.42.0.15-9886&amp;noUDP&amp;sock=6207_60d7_3&gt; ... 001 (011.001.000) 03/05 22:37:57 Job executing on host: &lt;10.42.0.8:9886?sock=30363_868c&gt; ... 006 (011.001.000) 03/05 22:38:07 Image size of job updated: 1 8 - MemoryUsage of job (MB) 7560 - ResidentSetSize of job (KB) ... 005 (011.001.000) 03/05 22:38:09 Job terminated. (1) Normal termination (return value 0) Usr 0 00:00:00, Sys 0 00:00:00 - Run Remote Usage Usr 0 00:00:00, Sys 0 00:00:00 - Run Local Usage Usr 0 00:00:00, Sys 0 00:00:00 - Total Remote Usage Usr 0 00:00:00, Sys 0 00:00:00 - Total Local Usage 132 - Run Bytes Sent By Job 163 - Run Bytes Received By Job 132 - Total Bytes Sent By Job 163 - Total Bytes Received By Job Partitionable Resources : Usage Request Allocated Cpus : 1 1 Disk (KB) : 9 1 893677 Memory (MB) : 8 1 1 ... 4.5.5.0.3.1 References: Condor Submit Jobs (Official Docs) Multi Node Condor Pool (Blog) Simple Condor Cluster (Blog) Condor Examples of Security Configurations (Official Docs) Install Docker Community Edition https://docs.docker.com/install/linux/docker-ce/ubuntu/ "]
]
